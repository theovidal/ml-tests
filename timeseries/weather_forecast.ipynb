{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weather forecast - A timeseries example\n",
    "\n",
    "This notebook was written as an application of Chapter 10 (Deep learning for timeseries) of _Deep learning with Python_ from Fran√ßois Chollet."
   ],
   "id": "62dc25551337d5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:29.363946Z",
     "start_time": "2024-08-12T13:22:29.360259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner"
   ],
   "id": "46965ddb6111ba8f",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Download and import the data",
   "id": "afd31cab6cc6e9fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Detect if a file exists\n",
    "if not os.path.isfile('jena_climate_2009_2016.csv.zip'):\n",
    "    !wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "    !unzip jena_climate_2009_2016.csv.zip"
   ],
   "id": "52b6bd8ba059c053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:36.347644Z",
     "start_time": "2024-08-12T13:22:34.043127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = {\n",
    "    \"datetime\": \"Date Time\",\n",
    "    \"p\": \"p (mbar)\",\n",
    "    \"t\": \"T (degC)\",\n",
    "    \"tpot\": \"Tpot (K)\",\n",
    "    \"tdew\": \"Tdew (degC)\",\n",
    "    \"rh\": \"rh (%)\",\n",
    "    \"vpmax\": \"VPmax (mbar)\",\n",
    "    \"vpact\": \"VPact (mbar)\",\n",
    "    \"vpdef\": \"VPdef (mbar)\",\n",
    "    \"sh\": \"sh (g/kg)\",\n",
    "    \"h2Oc\": \"H2OC (mmol/mol)\",\n",
    "    \"rho\": \"rho (g/m**3)\",\n",
    "    \"wv\": \"wv (m/s)\",\n",
    "    \"max_wv\": \"max. wv (m/s)\",\n",
    "    \"wd\": \"wd (deg)\"\n",
    "}\n",
    "\n",
    "jena_climate_2009_2016 = pd.read_csv(\n",
    "    'jena_climate_2009_2016.csv',\n",
    "    sep=',',\n",
    "    names=columns.keys(),\n",
    "    skiprows=1)\n",
    "jena_climate_2009_2016.datetime = pd.to_datetime(jena_climate_2009_2016.datetime, format='%d.%m.%Y %H:%M:%S')\n",
    "nb_rows = len(jena_climate_2009_2016)\n",
    "nb_cols = len(jena_climate_2009_2016.columns)\n",
    "jena_climate_2009_2016"
   ],
   "id": "3bf7e61f42a06b5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  datetime        p     t    tpot  tdew     rh  vpmax  vpact  \\\n",
       "0      2009-01-01 00:10:00   996.52 -8.02  265.40 -8.90  93.30   3.33   3.11   \n",
       "1      2009-01-01 00:20:00   996.57 -8.41  265.01 -9.28  93.40   3.23   3.02   \n",
       "2      2009-01-01 00:30:00   996.53 -8.51  264.91 -9.31  93.90   3.21   3.01   \n",
       "3      2009-01-01 00:40:00   996.51 -8.31  265.12 -9.07  94.20   3.26   3.07   \n",
       "4      2009-01-01 00:50:00   996.51 -8.27  265.15 -9.04  94.10   3.27   3.08   \n",
       "...                    ...      ...   ...     ...   ...    ...    ...    ...   \n",
       "420446 2016-12-31 23:20:00  1000.07 -4.05  269.10 -8.13  73.10   4.52   3.30   \n",
       "420447 2016-12-31 23:30:00   999.93 -3.35  269.81 -8.06  69.71   4.77   3.32   \n",
       "420448 2016-12-31 23:40:00   999.82 -3.16  270.01 -8.21  67.91   4.84   3.28   \n",
       "420449 2016-12-31 23:50:00   999.81 -4.23  268.94 -8.53  71.80   4.46   3.20   \n",
       "420450 2017-01-01 00:00:00   999.82 -4.82  268.36 -8.42  75.70   4.27   3.23   \n",
       "\n",
       "        vpdef    sh  h2Oc      rho    wv  max_wv     wd  \n",
       "0        0.22  1.94  3.12  1307.75  1.03    1.75  152.3  \n",
       "1        0.21  1.89  3.03  1309.80  0.72    1.50  136.1  \n",
       "2        0.20  1.88  3.02  1310.24  0.19    0.63  171.6  \n",
       "3        0.19  1.92  3.08  1309.19  0.34    0.50  198.0  \n",
       "4        0.19  1.92  3.09  1309.00  0.32    0.63  214.3  \n",
       "...       ...   ...   ...      ...   ...     ...    ...  \n",
       "420446   1.22  2.06  3.30  1292.98  0.67    1.52  240.0  \n",
       "420447   1.44  2.07  3.32  1289.44  1.14    1.92  234.3  \n",
       "420448   1.55  2.05  3.28  1288.39  1.08    2.00  215.2  \n",
       "420449   1.26  1.99  3.20  1293.56  1.49    2.16  225.8  \n",
       "420450   1.04  2.01  3.23  1296.38  1.23    1.96  184.9  \n",
       "\n",
       "[420451 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "      <th>tpot</th>\n",
       "      <th>tdew</th>\n",
       "      <th>rh</th>\n",
       "      <th>vpmax</th>\n",
       "      <th>vpact</th>\n",
       "      <th>vpdef</th>\n",
       "      <th>sh</th>\n",
       "      <th>h2Oc</th>\n",
       "      <th>rho</th>\n",
       "      <th>wv</th>\n",
       "      <th>max_wv</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.30</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.40</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.90</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.10</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420446</th>\n",
       "      <td>2016-12-31 23:20:00</td>\n",
       "      <td>1000.07</td>\n",
       "      <td>-4.05</td>\n",
       "      <td>269.10</td>\n",
       "      <td>-8.13</td>\n",
       "      <td>73.10</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1292.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.52</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420447</th>\n",
       "      <td>2016-12-31 23:30:00</td>\n",
       "      <td>999.93</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>269.81</td>\n",
       "      <td>-8.06</td>\n",
       "      <td>69.71</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1289.44</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.92</td>\n",
       "      <td>234.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420448</th>\n",
       "      <td>2016-12-31 23:40:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>270.01</td>\n",
       "      <td>-8.21</td>\n",
       "      <td>67.91</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1288.39</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>215.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420449</th>\n",
       "      <td>2016-12-31 23:50:00</td>\n",
       "      <td>999.81</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>268.94</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>71.80</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1293.56</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.16</td>\n",
       "      <td>225.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420450</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>268.36</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>75.70</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1296.38</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>184.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420451 rows √ó 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Analyze the data\n",
    "\n",
    "We want to know what are the main patterns in order to correctly analyze the coherence of our model's predictions"
   ],
   "id": "40dcb53d7fe2b2e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General purpose plots: get an insight of global tendencies over years",
   "id": "9014f77911aa0252"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nb_cols // 3, sharex=True, figsize=[10 * 3, 6 * nb_cols // 3])\n",
    "\n",
    "for i, col in enumerate(jena_climate_2009_2016.columns):\n",
    "    if col == \"datetime\":\n",
    "        continue\n",
    "    ax = axes[i // 3, i % 3]\n",
    "        \n",
    "    jena_climate_2009_2016.plot(x='datetime', y=col, ax=ax, label=columns[col], color=colors[i % (len(colors))])\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(columns[col])\n",
    "    \n",
    "fig.tight_layout()"
   ],
   "id": "78b25b91f0385f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Link between temperature, pressure and humidity over a year",
   "id": "1e8fca40afa2ea7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Observing the variation at some day\n",
    "reference = 2 * nb_rows / 5\n",
    "nb_days = 31 * 3\n",
    "\n",
    "start = int(reference)\n",
    "end = int(6 * 24 * nb_days + reference) \n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 6 * 3), sharex=True)\n",
    "\n",
    "for i, col in enumerate(['t', 'p', 'rh']):\n",
    "    jena_climate_2009_2016.iloc[start:end].plot(x='datetime', label=columns[col], y=col, ax=axes[i])\n",
    "\n",
    "fig.tight_layout()"
   ],
   "id": "55e85b66c38f74ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Prepare data for the pipeline\n",
    "\n",
    "Be careful to remove the temperature from the dataset, as it's what we want to predict...\n",
    "\n",
    "We also don't consider the datetime column, as we can totally rely solely on indexes"
   ],
   "id": "3ead67f0e519cc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the dataset",
   "id": "502f0a159c8e65ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:41.202613Z",
     "start_time": "2024-08-12T13:22:41.043022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_proportion = 0.5\n",
    "validation_proportion = 0.25\n",
    "test_split = 1 - training_proportion - validation_proportion\n",
    "\n",
    "training_index = int(training_proportion * nb_rows)\n",
    "validation_index = training_index + int(validation_proportion * nb_rows)\n",
    "\n",
    "raw_data = jena_climate_2009_2016.copy()\n",
    "temperature = raw_data.t\n",
    "raw_data.pop('datetime')"
   ],
   "id": "a6dcdf45a1bb835",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2009-01-01 00:10:00\n",
       "1        2009-01-01 00:20:00\n",
       "2        2009-01-01 00:30:00\n",
       "3        2009-01-01 00:40:00\n",
       "4        2009-01-01 00:50:00\n",
       "                 ...        \n",
       "420446   2016-12-31 23:20:00\n",
       "420447   2016-12-31 23:30:00\n",
       "420448   2016-12-31 23:40:00\n",
       "420449   2016-12-31 23:50:00\n",
       "420450   2017-01-01 00:00:00\n",
       "Name: datetime, Length: 420451, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalizing all the data\n",
    "\n",
    "We normalize all the values (they're all numerical, it's easy) according to the mean and standard deviation of the training data."
   ],
   "id": "84c44c81cc4abf04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:42.605089Z",
     "start_time": "2024-08-12T13:22:42.364981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = raw_data[:training_index].mean()\n",
    "std = raw_data[:training_index].std()\n",
    "raw_data = (raw_data - mean) / std\n",
    "raw_data[:training_index]"
   ],
   "id": "bb6fb8ef75398978",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               p         t      tpot      tdew        rh     vpmax     vpact  \\\n",
       "0       0.913649 -1.920636 -1.974488 -1.866254  1.048015 -1.291316 -1.467152   \n",
       "1       0.919528 -1.965100 -2.018478 -1.919925  1.054028 -1.304472 -1.488855   \n",
       "2       0.914825 -1.976501 -2.029758 -1.924162  1.084097 -1.307103 -1.491266   \n",
       "3       0.912474 -1.953699 -2.006071 -1.890265  1.102138 -1.300525 -1.476798   \n",
       "4       0.912474 -1.949139 -2.002687 -1.886027  1.096124 -1.299210 -1.474386   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "210220 -0.199796 -0.171691 -0.155101 -0.427015 -0.628593 -0.380947 -0.599035   \n",
       "210221 -0.183336 -0.148889 -0.133670 -0.421365 -0.668884 -0.362529 -0.594212   \n",
       "210222 -0.172754 -0.144328 -0.130287 -0.418540 -0.676101 -0.358583 -0.594212   \n",
       "210223 -0.163348 -0.153449 -0.140438 -0.412891 -0.643627 -0.366476 -0.589389   \n",
       "210224 -0.166875 -0.173971 -0.160741 -0.410066 -0.587700 -0.382263 -0.584566   \n",
       "\n",
       "           vpdef        sh      h2Oc       rho        wv    max_wv        wd  \n",
       "0      -0.782343 -1.470122 -1.472032  2.124151 -0.730165 -0.779351 -0.281192  \n",
       "1      -0.784440 -1.489114 -1.493462  2.172914 -0.932305 -0.886968 -0.469893  \n",
       "2      -0.786537 -1.492912 -1.495843  2.183381 -1.277899 -1.261473 -0.056383  \n",
       "3      -0.788633 -1.477719 -1.481556  2.158404 -1.180089 -1.317434  0.251128  \n",
       "4      -0.788633 -1.477719 -1.479175  2.153885 -1.193130 -1.261473  0.440993  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "210220 -0.086271 -0.596521 -0.598159  0.102950  1.617266  1.398809  0.181239  \n",
       "210221 -0.061112 -0.592722 -0.591016  0.086299  1.930257  1.708745  0.427015  \n",
       "210222 -0.054822 -0.592722 -0.591016  0.084634  1.695513  1.329935  0.258117  \n",
       "210223 -0.071595 -0.585126 -0.586254  0.095100  1.506415  1.054436  0.117174  \n",
       "210224 -0.100948 -0.585126 -0.583873  0.112703  1.206465  1.071655  0.019330  \n",
       "\n",
       "[210225 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "      <th>tpot</th>\n",
       "      <th>tdew</th>\n",
       "      <th>rh</th>\n",
       "      <th>vpmax</th>\n",
       "      <th>vpact</th>\n",
       "      <th>vpdef</th>\n",
       "      <th>sh</th>\n",
       "      <th>h2Oc</th>\n",
       "      <th>rho</th>\n",
       "      <th>wv</th>\n",
       "      <th>max_wv</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913649</td>\n",
       "      <td>-1.920636</td>\n",
       "      <td>-1.974488</td>\n",
       "      <td>-1.866254</td>\n",
       "      <td>1.048015</td>\n",
       "      <td>-1.291316</td>\n",
       "      <td>-1.467152</td>\n",
       "      <td>-0.782343</td>\n",
       "      <td>-1.470122</td>\n",
       "      <td>-1.472032</td>\n",
       "      <td>2.124151</td>\n",
       "      <td>-0.730165</td>\n",
       "      <td>-0.779351</td>\n",
       "      <td>-0.281192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.919528</td>\n",
       "      <td>-1.965100</td>\n",
       "      <td>-2.018478</td>\n",
       "      <td>-1.919925</td>\n",
       "      <td>1.054028</td>\n",
       "      <td>-1.304472</td>\n",
       "      <td>-1.488855</td>\n",
       "      <td>-0.784440</td>\n",
       "      <td>-1.489114</td>\n",
       "      <td>-1.493462</td>\n",
       "      <td>2.172914</td>\n",
       "      <td>-0.932305</td>\n",
       "      <td>-0.886968</td>\n",
       "      <td>-0.469893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914825</td>\n",
       "      <td>-1.976501</td>\n",
       "      <td>-2.029758</td>\n",
       "      <td>-1.924162</td>\n",
       "      <td>1.084097</td>\n",
       "      <td>-1.307103</td>\n",
       "      <td>-1.491266</td>\n",
       "      <td>-0.786537</td>\n",
       "      <td>-1.492912</td>\n",
       "      <td>-1.495843</td>\n",
       "      <td>2.183381</td>\n",
       "      <td>-1.277899</td>\n",
       "      <td>-1.261473</td>\n",
       "      <td>-0.056383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.912474</td>\n",
       "      <td>-1.953699</td>\n",
       "      <td>-2.006071</td>\n",
       "      <td>-1.890265</td>\n",
       "      <td>1.102138</td>\n",
       "      <td>-1.300525</td>\n",
       "      <td>-1.476798</td>\n",
       "      <td>-0.788633</td>\n",
       "      <td>-1.477719</td>\n",
       "      <td>-1.481556</td>\n",
       "      <td>2.158404</td>\n",
       "      <td>-1.180089</td>\n",
       "      <td>-1.317434</td>\n",
       "      <td>0.251128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912474</td>\n",
       "      <td>-1.949139</td>\n",
       "      <td>-2.002687</td>\n",
       "      <td>-1.886027</td>\n",
       "      <td>1.096124</td>\n",
       "      <td>-1.299210</td>\n",
       "      <td>-1.474386</td>\n",
       "      <td>-0.788633</td>\n",
       "      <td>-1.477719</td>\n",
       "      <td>-1.479175</td>\n",
       "      <td>2.153885</td>\n",
       "      <td>-1.193130</td>\n",
       "      <td>-1.261473</td>\n",
       "      <td>0.440993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210220</th>\n",
       "      <td>-0.199796</td>\n",
       "      <td>-0.171691</td>\n",
       "      <td>-0.155101</td>\n",
       "      <td>-0.427015</td>\n",
       "      <td>-0.628593</td>\n",
       "      <td>-0.380947</td>\n",
       "      <td>-0.599035</td>\n",
       "      <td>-0.086271</td>\n",
       "      <td>-0.596521</td>\n",
       "      <td>-0.598159</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>1.617266</td>\n",
       "      <td>1.398809</td>\n",
       "      <td>0.181239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210221</th>\n",
       "      <td>-0.183336</td>\n",
       "      <td>-0.148889</td>\n",
       "      <td>-0.133670</td>\n",
       "      <td>-0.421365</td>\n",
       "      <td>-0.668884</td>\n",
       "      <td>-0.362529</td>\n",
       "      <td>-0.594212</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>-0.592722</td>\n",
       "      <td>-0.591016</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>1.930257</td>\n",
       "      <td>1.708745</td>\n",
       "      <td>0.427015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210222</th>\n",
       "      <td>-0.172754</td>\n",
       "      <td>-0.144328</td>\n",
       "      <td>-0.130287</td>\n",
       "      <td>-0.418540</td>\n",
       "      <td>-0.676101</td>\n",
       "      <td>-0.358583</td>\n",
       "      <td>-0.594212</td>\n",
       "      <td>-0.054822</td>\n",
       "      <td>-0.592722</td>\n",
       "      <td>-0.591016</td>\n",
       "      <td>0.084634</td>\n",
       "      <td>1.695513</td>\n",
       "      <td>1.329935</td>\n",
       "      <td>0.258117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210223</th>\n",
       "      <td>-0.163348</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.140438</td>\n",
       "      <td>-0.412891</td>\n",
       "      <td>-0.643627</td>\n",
       "      <td>-0.366476</td>\n",
       "      <td>-0.589389</td>\n",
       "      <td>-0.071595</td>\n",
       "      <td>-0.585126</td>\n",
       "      <td>-0.586254</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>1.506415</td>\n",
       "      <td>1.054436</td>\n",
       "      <td>0.117174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210224</th>\n",
       "      <td>-0.166875</td>\n",
       "      <td>-0.173971</td>\n",
       "      <td>-0.160741</td>\n",
       "      <td>-0.410066</td>\n",
       "      <td>-0.587700</td>\n",
       "      <td>-0.382263</td>\n",
       "      <td>-0.584566</td>\n",
       "      <td>-0.100948</td>\n",
       "      <td>-0.585126</td>\n",
       "      <td>-0.583873</td>\n",
       "      <td>0.112703</td>\n",
       "      <td>1.206465</td>\n",
       "      <td>1.071655</td>\n",
       "      <td>0.019330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210225 rows √ó 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a temporal sliding window\n",
    "\n",
    "As stated in the book, we'll use the past five days to predict a temperature 24 hours in the future.\n",
    "\n",
    "We only want one point per hour in the future, so we skip 6 timesteps (of 10 minutes each)\n",
    "\n",
    "The datasets will now contain :\n",
    "- A samples matrix, of shape (samples, timesteps, features)\n",
    "- A predictions vector with the temperatures corresponding to each sample"
   ],
   "id": "3ed1c0993c8dc275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:44.337322Z",
     "start_time": "2024-08-12T13:22:43.982805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampling_rate = 6  # Each input and output point will be taken every 6 timesteps (one per hour)\n",
    "sequence_length = 24 * 5\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)  # Delay to start target values, in number of timesteps ; TODO: understand the -1\n",
    "batch_size = 256\n",
    "\n",
    "timeseries_kwargs = {\n",
    "    'data': raw_data[:-delay], # Don't include the last sequence\n",
    "    'targets': temperature[delay:],\n",
    "    'sampling_rate': sampling_rate,\n",
    "    'sequence_length': sequence_length,\n",
    "    'batch_size': batch_size, # Shuffle the samples between them, not inside a sample of course\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "train_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    end_index=training_index,\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    start_index=training_index,  # Start and end index are also applied to targets\n",
    "    end_index=validation_index,\n",
    ")\n",
    "\n",
    "test_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    start_index=validation_index,\n",
    ")"
   ],
   "id": "70e2848c3b4e426a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Test different models\n",
    "\n",
    "In this part, we will dive into many models, starting from the most na√Øve one to the most complex, in order to evaluate the gains of each one versus its computation time"
   ],
   "id": "cbec9452109d2ea4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Skeleton\n",
    "\n",
    "We first define some helper functions to compile, fit and save our models:"
   ],
   "id": "32323ae02fe12acf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:47.633581Z",
     "start_time": "2024-08-12T13:22:47.624499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compile_model(\n",
    "        model,\n",
    "        learning_rate=1e-3,\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=None):\n",
    "\n",
    "    if metrics is None:\n",
    "        metrics = []\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                training_data,\n",
    "                epochs=100,\n",
    "                callbacks=None,\n",
    "                early_stopping=None,\n",
    "                validation_split=0.2,\n",
    "                validation_data=None,\n",
    "                name='model',\n",
    "                log_dir='logs/fit'\n",
    "                ):\n",
    "\n",
    "    if callbacks is None:\n",
    "        callbacks = []\n",
    "        \n",
    "    if early_stopping is not None:\n",
    "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stopping))\n",
    "\n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(f'models/{name}.keras', save_best_only=True))\n",
    "    callbacks.append(tf.keras.callbacks.BackupAndRestore(backup_dir=f'/tmp/backup/{name}--{date}'))\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=f'{log_dir}/{name}--{date}', histogram_freq=1))\n",
    "        \n",
    "    # We don't have \"batch size\" here as the batches were already made during data preparation\n",
    "    kwargs = {\n",
    "        'epochs': epochs,\n",
    "        'callbacks': callbacks,\n",
    "    }\n",
    "    if validation_data is not None:\n",
    "        kwargs['validation_data'] = validation_data\n",
    "    else:\n",
    "        kwargs['validation_split'] = validation_split\n",
    "\n",
    "    model.fit(\n",
    "        training_data,\n",
    "        **kwargs\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "\n",
    "def create_and_process_model(name, build_function, training_data=train_data, learning_rate=1e-3):\n",
    "    model = build_function()\n",
    "    # For the loss, we use MSE as it's more stable around 0 (for gradient calculation)\n",
    "    # But for evaluation, we prefer using MAE which is clearly interpretable as an error on average\n",
    "    compile_model(\n",
    "        model, \n",
    "        learning_rate=learning_rate,\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    train_model(\n",
    "        model,\n",
    "        training_data,\n",
    "        epochs=100,\n",
    "        validation_data=val_data,\n",
    "        name=name\n",
    "    )\n",
    "    \n",
    "    \n",
    "def test_best_model(name):\n",
    "    best_model = tf.keras.models.load_model(f'models/{name}.keras')\n",
    "    print(f'MAE for {name}: {best_model.evaluate(test_data)[1]:.2f}')"
   ],
   "id": "f97215381dba70cd",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Baseline\n",
    "\n",
    "We must then create a more robust model that performs better on the same metrics.\n",
    "\n",
    "The baseline approach consists of translating the temperature 24 hours to the future and use them as predictions. So in our samples, we use the last temperature measures (to be exactly 24 hours apart from the prediction).\n",
    "\n",
    "We use the Mean Absolute Error (MSE) metric, i.e. sum(|prediction - target|) / nb_samples"
   ],
   "id": "60db64d6d0ecaf97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_baseline_method(dataset):\n",
    "    total_absolute_error = 0.0\n",
    "    nb_samples = 0\n",
    "    for samples, targets in dataset:\n",
    "        # We want all the samples of the batch, the last timestep, and the temperature column\n",
    "        # Be careful: we didn't normalize the targets (temperature array), so we have to de-normalize the prediction\n",
    "        predictions = samples[:, -1, 1] * std.t + mean.t\n",
    "        total_absolute_error += np.sum(np.abs(predictions - targets))\n",
    "        nb_samples += samples.shape[0]  # Reflex: use the shape instead of far variables or hard-coded values\n",
    "    return total_absolute_error / nb_samples\n",
    "        \n",
    "print(f\"Validation MSE (in ¬∞C): {evaluate_baseline_method(val_data):.3f}\")\n",
    "print(f\"Test MSE (in ¬∞C): {evaluate_baseline_method(test_data):.3f}\")"
   ],
   "id": "99376a7a3eac69a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that by using our baseline method, our predictions would be off by around two and a half degrees in average. This is not bad, but it can definitely be improved.",
   "id": "2d7e4dd8acac8517"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dense\n",
    "\n",
    "Note: we don't use an activation function for the last layer, as we are facing a regression problem."
   ],
   "id": "5b140b0de17ca5f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_dense():\n",
    "    # raw_data.shape[1:] skips the number of features to just get the shape of the input\n",
    "    # In this special case, we could replace it by \"nb_columns\"\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    # Our network must deal with vectors, i.e. one-dimensional tensors ; so we flatten the input data\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "create_and_process_model('dense', create_dense)"
   ],
   "id": "22284f08acf44009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('dense')",
   "id": "3ed35d0d1337061e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that this model didn't really achieve a good performance compared to the baseline method. We have to seek for a more complex model.\n",
    "\n",
    "One of the reasons is the flattening : we remove the temporal information from the data, whereas this is crucial for our forecasting task."
   ],
   "id": "fef82c1a8fe4309c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1D-convolutional network\n",
    "\n",
    "The 1D convolution is well suited for timeseries (temporal convolution)."
   ],
   "id": "9daa6ac97aa69489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_convolutional():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    # Our network must deal with vectors, i.e. one-dimensional tensors ; so we flatten the input data\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    # We use convolution windows of 24 hours, as most of the patterns would be detected there\n",
    "    # in accordance to the relative continuity and periodicity of the parameters\n",
    "    # TODO: understand the consequence of \"padding='causal'\"\n",
    "    x = tf.keras.layers.Conv1D(8, 24, padding='causal', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool1D(2)(x)\n",
    "    # Don't forget to adapt the window size as we downsample\n",
    "    # = the model learns to detect more precise patterns\n",
    "    x = tf.keras.layers.Conv1D(8, 12, padding='causal', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(8, 6, padding='causal', activation='relu')(x)\n",
    "    # TODO: understand why we finish with a global average pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "create_and_process_model('convolutional', create_convolutional)"
   ],
   "id": "6efcda0ed857e574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('convolutional')",
   "id": "392a5ab54b44d159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model performs worse than the densely-connected one. This is simply caused by the convolution itself, that treats segments of data the same way, but the weather contains variations over days and months.",
   "id": "2ef073ebd0cb863d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First look at RNNs\n",
    "\n",
    "RNNs are better suited to forecast some data, as they intrinsically work with timesteps / a notion of order, which is crucial here."
   ],
   "id": "ece2f9c7d1b5a213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_simplernn():\n",
    "    # The SimpleRNN layer can process sequences of arbitrary length\n",
    "    inputs = tf.keras.Input(shape=(None, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.SimpleRNN(16)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('simple_rnn', create_simplernn)\n"
   ],
   "id": "31570c532f1a2187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('simple_rnn')",
   "id": "64b4241efc710561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That's better than the baseline approach, meaning that machine learning has a real added value",
   "id": "645d8d46e6bd04c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Long Short-Term Memory (LSTM)",
   "id": "1c83955dd9a935db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_lstm():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(16)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('lstm', create_lstm)"
   ],
   "id": "32daedf96a609b2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('lstm')",
   "id": "233be17a249aced2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's quite a good model, but there is a big problem: if we look at the loss and MAE graphs, we see that training metrics always decrease, whereas validation ones start to increase. Both are diverging rapidly: the model is overfitting!",
   "id": "cb0d99e74c8ef289"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adding recurrent dropout\n",
    "\n",
    "We can now increase the number of units in the LSTM layer, as the dropout will prevent a quick overfitting in the other case.\n",
    "\n",
    "We also add a Dropout layer as usual to finally regularize the output of the LSTM layer."
   ],
   "id": "a23e03687ce97355"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_lstm_dropout():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('lstm_dropout', create_lstm_dropout)"
   ],
   "id": "d05f9d0afedfa9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('lstm_dropout')",
   "id": "d16ff26d9f64528d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaling our model",
   "id": "ed78b0757c6dc033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_gru():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.GRU(32, recurrent_dropout=0.5)(inputs)\n",
    "    #x = tf.keras.layers.GRU(32, recurrent_dropout=0.5)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('gru', create_gru)"
   ],
   "id": "d4ac4f525aedcba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('gru')",
   "id": "30d38cba88ff5323",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reversed-order RNN\n",
    "\n",
    "Before moving on, let's test the influence of reversing the input sequence, to see if the chronological order really matters."
   ],
   "id": "e18c1b86c064a51e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reversed_timeseries_kwargs = {\n",
    "    'data': raw_data[:-delay][::-1], # Don't include the last sequence\n",
    "    'targets': temperature[delay:][::-1],\n",
    "    'sampling_rate': sampling_rate,\n",
    "    'sequence_length': sequence_length,\n",
    "    'batch_size': batch_size, # Shuffle the samples between them, not inside a sample of course\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "reversed_train_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **reversed_timeseries_kwargs,\n",
    "    end_index=training_index,\n",
    ")"
   ],
   "id": "ee89cfdc09154161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_and_process_model('reversed_lstm', create_lstm, training_data=reversed_train_data)",
   "id": "1b71d55d21a98d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('reversed_lstm')",
   "id": "d37d83dfd5be7a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It's not really convincing as-is: indeed, the predictions are more tied to most recent weather conditions than past ones.\n",
    "\n",
    "The anti-chronological order could still provide valuable information if we combine it to the chronological order."
   ],
   "id": "aeb2bb59acf8dc8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bidirectional RNN",
   "id": "7a3db06c087471c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_bidirectional():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, recurrent_dropout=0.5))(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('bidirectional', create_bidirectional)"
   ],
   "id": "10f889e7b3115a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('bidirectional')",
   "id": "17989e4246a733d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This model is more complex, thus overfitting earlier\n",
    "- The anti-chronological information is poluting the chronological one here: the past is way less important than the recent for this task"
   ],
   "id": "dd76a387e931f9ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "We can't really achieve better performance than the baseline: we only have weather data at one point, however conditions are clearly influenced by other places.\n",
    "\n",
    "Machine learning still is relevant to predict a future where the past contains information and can influence the rest."
   ],
   "id": "697dcc30b0cb90f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The final model\n",
    "\n",
    "We will first seek for the best hyperparameters, by using KerasTuner."
   ],
   "id": "4c315dfad2a813f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:15:49.515688Z",
     "start_time": "2024-08-12T19:15:49.496580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_final(\n",
    "        recurrent_dropout=0.6,\n",
    "        units=32,\n",
    "        l2_units=None,\n",
    "        end_neural=True\n",
    "    ):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(units=units, recurrent_dropout=recurrent_dropout)(inputs)\n",
    "\n",
    "    if l2_units is not None:\n",
    "       x = tf.keras.layers.LSTM(units=l2_units, recurrent_dropout=recurrent_dropout)(inputs)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    if end_neural:\n",
    "        x = tf.keras.layers.Dense(16)(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def search_final(hp):\n",
    "    model = create_final(\n",
    "        recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.2, max_value=0.7, default=0.5, step=0.1),\n",
    "        units=hp.Int('units', min_value=32, max_value=64, step=32),\n",
    "        l2_units=hp.Int('units', min_value=32, max_value=64, step=32),\n",
    "        end_neural=hp.Boolean('end_neural'),\n",
    "    )\n",
    "    learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ],
   "id": "2dc93e8b4e34a1d4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuner = keras_tuner.Hyperband(\n",
    "    hypermodel=create_final,\n",
    "    objective='val_mae',\n",
    "    max_epochs=15,\n",
    "    overwrite=True,\n",
    "    directory='model_search',\n",
    "    project_name='weather_forecasting'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=f'logs/fit/final--{date}', histogram_freq=1)\n",
    "]\n",
    "\n",
    "tuner.search(train_data, validation_data=val_data, callbacks=callbacks)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ],
   "id": "64779fe0efbe5eca",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 Complete [00h 06m 20s]\n",
      "val_mae: 2.3841261863708496\n",
      "\n",
      "Best val_mae So Far: 2.2665553092956543\n",
      "Total elapsed time: 04h 27m 13s\n",
      "\n",
      "Search: Running Trial #48\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.4               |0.6               |recurrent_dropout\n",
      "64                |32                |units\n",
      "True              |False             |l2\n",
      "True              |True              |end_neural\n",
      "0.00049269        |0.0045213         |learning_rate\n",
      "6                 |6                 |tuner/epochs\n",
      "0                 |2                 |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 168ms/step - loss: 38.0526 - mae: 4.5436 - val_loss: 9.2990 - val_mae: 2.3805\n",
      "Epoch 2/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m136s\u001B[0m 166ms/step - loss: 15.3070 - mae: 3.0477 - val_loss: 9.1808 - val_mae: 2.3557\n",
      "Epoch 3/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m137s\u001B[0m 167ms/step - loss: 14.4910 - mae: 2.9561 - val_loss: 9.0417 - val_mae: 2.3349\n",
      "Epoch 4/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m135s\u001B[0m 165ms/step - loss: 14.1422 - mae: 2.9228 - val_loss: 8.8647 - val_mae: 2.3100\n",
      "Epoch 5/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 170ms/step - loss: 13.7686 - mae: 2.8805 - val_loss: 8.8248 - val_mae: 2.3057\n",
      "Epoch 6/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 13.5495 - mae: 2.8589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m date \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      4\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m),\n\u001B[1;32m      5\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogs/fit/final--\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, histogram_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m ]\n\u001B[0;32m----> 8\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m best_hps \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_hyperparameters(num_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_end(trial)\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001B[0m, in \u001B[0;36mBaseTuner._try_run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m         trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mCOMPLETED\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001B[0m, in \u001B[0;36mBaseTuner._run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[0;32m--> 239\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_trial(trial\u001B[38;5;241m.\u001B[39mtrial_id)\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mexists(\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    242\u001B[0m     ):\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001B[39;00m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001B[39;00m\n\u001B[1;32m    245\u001B[0m         \u001B[38;5;66;03m# use case. No further action needed in this case.\u001B[39;00m\n\u001B[1;32m    246\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    247\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe use case of calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    254\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    255\u001B[0m         )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001B[0m, in \u001B[0;36mHyperband.run_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    425\u001B[0m     fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtuner/epochs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    426\u001B[0m     fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtuner/initial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001B[0m, in \u001B[0;36mTuner.run_trial\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    312\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(model_checkpoint)\n\u001B[1;32m    313\u001B[0m     copied_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[0;32m--> 314\u001B[0m     obj_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_and_fit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcopied_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m     histories\u001B[38;5;241m.\u001B[39mappend(obj_value)\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m histories\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001B[0m, in \u001B[0;36mTuner._build_and_fit_model\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[1;32m    232\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[0;32m--> 233\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# Save the build config for model loading later.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmulti_backend():\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[0;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:343\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_epoch_iterator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_epoch_iterator \u001B[38;5;241m=\u001B[39m TFEpochIterator(\n\u001B[1;32m    334\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m    335\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    341\u001B[0m         shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    342\u001B[0m     )\n\u001B[0;32m--> 343\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    355\u001B[0m }\n\u001B[1;32m    356\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:429\u001B[0m, in \u001B[0;36mTensorFlowTrainer.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    428\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m--> 429\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    430\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    431\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_end(step, logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1567\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Trial 47 Complete [00h 06m 20s]\n",
    "\n",
    "val_mae: 2.3841261863708496\n",
    "\n",
    "\n",
    "Best val_mae So Far: 2.2665553092956543\n",
    "\n",
    "Total elapsed time: 04h 27m 13s\n",
    "\n",
    "\n",
    "Search: Running Trial #48\n",
    "\n",
    "\n",
    "| Value      | Best Value So Far | Hyperparameter      |\n",
    "|------------|-------------------|---------------------|\n",
    "| 0.4        | 0.6               | recurrent_dropout   |\n",
    "| 64         | 32                | units               |\n",
    "| True       | False             | l2                  |\n",
    "| True       | True              | end_neural          |\n",
    "| 0.00049269 | 0.0045213         | learning_rate       |\n",
    "| 6          | 6                 | tuner/epochs        |\n",
    "| 0          | 2                 | tuner/initial_epoch |\n",
    "| 2          | 3                 | tuner/bracket       |\n",
    "| 0          | 1                 | tuner/round         |\n",
    "\n",
    "We can now use these parameters to create our model."
   ],
   "id": "84b27a8551991150"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:47:30.872028Z",
     "start_time": "2024-08-12T19:15:53.649498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model = create_final(\n",
    "    recurrent_dropout=0.6,\n",
    "    units=32,\n",
    "    l2_units=None,\n",
    "    end_neural=True\n",
    ")\n",
    "\n",
    "compile_model(\n",
    "    final_model, \n",
    "    learning_rate=45e-4,\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "print(final_model.summary())\n",
    "train_model(\n",
    "    final_model,\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    validation_data=val_data,\n",
    "    name='final'\n",
    ")"
   ],
   "id": "e1af7b3031a3961b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m‚îÉ\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m‚îÉ\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m120\u001B[0m, \u001B[38;5;34m14\u001B[0m)        ‚îÇ             \u001B[38;5;34m0\u001B[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             ‚îÇ         \u001B[38;5;34m6,016\u001B[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             ‚îÇ             \u001B[38;5;34m0\u001B[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             ‚îÇ           \u001B[38;5;34m528\u001B[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             ‚îÇ             \u001B[38;5;34m0\u001B[0m ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 ‚îÇ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              ‚îÇ            \u001B[38;5;34m17\u001B[0m ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)                    </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">       Param # </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m6,561\u001B[0m (25.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,561</span> (25.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m6,561\u001B[0m (25.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,561</span> (25.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m96s\u001B[0m 114ms/step - loss: 23.2959 - mae: 3.6314 - val_loss: 9.2714 - val_mae: 2.3586\n",
      "Epoch 2/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m102s\u001B[0m 124ms/step - loss: 14.9055 - mae: 2.9945 - val_loss: 10.0066 - val_mae: 2.4470\n",
      "Epoch 3/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m124s\u001B[0m 103ms/step - loss: 14.1885 - mae: 2.9214 - val_loss: 8.9559 - val_mae: 2.3192\n",
      "Epoch 4/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 79ms/step - loss: 13.7758 - mae: 2.8852 - val_loss: 9.6568 - val_mae: 2.4123\n",
      "Epoch 5/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 154ms/step - loss: 13.4369 - mae: 2.8447 - val_loss: 9.0105 - val_mae: 2.3274\n",
      "Epoch 6/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m87s\u001B[0m 107ms/step - loss: 13.2315 - mae: 2.8274 - val_loss: 8.7945 - val_mae: 2.2894\n",
      "Epoch 7/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 76ms/step - loss: 13.1199 - mae: 2.8136 - val_loss: 8.7541 - val_mae: 2.2909\n",
      "Epoch 8/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m106s\u001B[0m 129ms/step - loss: 13.0002 - mae: 2.7981 - val_loss: 9.0692 - val_mae: 2.3297\n",
      "Epoch 9/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m87s\u001B[0m 107ms/step - loss: 12.9517 - mae: 2.7953 - val_loss: 9.1753 - val_mae: 2.3475\n",
      "Epoch 10/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m90s\u001B[0m 110ms/step - loss: 12.8448 - mae: 2.7837 - val_loss: 9.0116 - val_mae: 2.3189\n",
      "Epoch 11/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 91ms/step - loss: 12.7897 - mae: 2.7742 - val_loss: 8.7945 - val_mae: 2.2994\n",
      "Epoch 12/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m96s\u001B[0m 117ms/step - loss: 12.6584 - mae: 2.7643 - val_loss: 9.0947 - val_mae: 2.3399\n",
      "Epoch 13/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 137ms/step - loss: 12.6384 - mae: 2.7588 - val_loss: 9.1939 - val_mae: 2.3433\n",
      "Epoch 14/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m114s\u001B[0m 139ms/step - loss: 12.5869 - mae: 2.7528 - val_loss: 8.9332 - val_mae: 2.3035\n",
      "Epoch 15/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m145s\u001B[0m 142ms/step - loss: 12.4651 - mae: 2.7406 - val_loss: 9.1570 - val_mae: 2.3451\n",
      "Epoch 16/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 108ms/step - loss: 12.5049 - mae: 2.7453 - val_loss: 9.2063 - val_mae: 2.3393\n",
      "Epoch 17/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 96ms/step - loss: 12.4672 - mae: 2.7405 - val_loss: 10.1540 - val_mae: 2.4550\n",
      "Epoch 18/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m84s\u001B[0m 102ms/step - loss: 12.4398 - mae: 2.7390 - val_loss: 9.4688 - val_mae: 2.3696\n",
      "Epoch 19/100\n",
      "\u001B[1m564/819\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[1m25s\u001B[0m 100ms/step - loss: 12.4493 - mae: 2.7344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 15\u001B[0m\n\u001B[1;32m      8\u001B[0m compile_model(\n\u001B[1;32m      9\u001B[0m     final_model, \n\u001B[1;32m     10\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m45e-4\u001B[39m,\n\u001B[1;32m     11\u001B[0m     loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mMeanSquaredError(),\n\u001B[1;32m     12\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(final_model\u001B[38;5;241m.\u001B[39msummary())\n\u001B[0;32m---> 15\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfinal_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfinal\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     21\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[50], line 47\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, training_data, epochs, callbacks, early_stopping, validation_split, validation_data, name, log_dir)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     45\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_split\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m validation_split\n\u001B[0;32m---> 47\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    317\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 318\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    320\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1567\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:47:59.137045Z",
     "start_time": "2024-08-12T19:47:34.440609Z"
    }
   },
   "cell_type": "code",
   "source": "test_best_model('final')",
   "id": "edb1fdb23447e356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m405/405\u001B[0m \u001B[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 59ms/step - loss: 9.7388 - mae: 2.4380\n",
      "MAE for final: 2.44\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
