{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Weather forecast - A timeseries example\n",
    "\n",
    "This notebook was written as an application of Chapter 10 (Deep learning for timeseries) of _Deep learning with Python_ from François Chollet."
   ],
   "id": "62dc25551337d5c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:29.363946Z",
     "start_time": "2024-08-12T13:22:29.360259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras_tuner"
   ],
   "id": "46965ddb6111ba8f",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Download and import the data",
   "id": "afd31cab6cc6e9fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Detect if a file exists\n",
    "if not os.path.isfile('jena_climate_2009_2016.csv.zip'):\n",
    "    !wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
    "    !unzip jena_climate_2009_2016.csv.zip"
   ],
   "id": "52b6bd8ba059c053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:36.347644Z",
     "start_time": "2024-08-12T13:22:34.043127Z"
    }
   },
   "cell_type": "code",
   "source": [
    "columns = {\n",
    "    \"datetime\": \"Date Time\",\n",
    "    \"p\": \"p (mbar)\",\n",
    "    \"t\": \"T (degC)\",\n",
    "    \"tpot\": \"Tpot (K)\",\n",
    "    \"tdew\": \"Tdew (degC)\",\n",
    "    \"rh\": \"rh (%)\",\n",
    "    \"vpmax\": \"VPmax (mbar)\",\n",
    "    \"vpact\": \"VPact (mbar)\",\n",
    "    \"vpdef\": \"VPdef (mbar)\",\n",
    "    \"sh\": \"sh (g/kg)\",\n",
    "    \"h2Oc\": \"H2OC (mmol/mol)\",\n",
    "    \"rho\": \"rho (g/m**3)\",\n",
    "    \"wv\": \"wv (m/s)\",\n",
    "    \"max_wv\": \"max. wv (m/s)\",\n",
    "    \"wd\": \"wd (deg)\"\n",
    "}\n",
    "\n",
    "jena_climate_2009_2016 = pd.read_csv(\n",
    "    'jena_climate_2009_2016.csv',\n",
    "    sep=',',\n",
    "    names=columns.keys(),\n",
    "    skiprows=1)\n",
    "jena_climate_2009_2016.datetime = pd.to_datetime(jena_climate_2009_2016.datetime, format='%d.%m.%Y %H:%M:%S')\n",
    "nb_rows = len(jena_climate_2009_2016)\n",
    "nb_cols = len(jena_climate_2009_2016.columns)\n",
    "jena_climate_2009_2016"
   ],
   "id": "3bf7e61f42a06b5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  datetime        p     t    tpot  tdew     rh  vpmax  vpact  \\\n",
       "0      2009-01-01 00:10:00   996.52 -8.02  265.40 -8.90  93.30   3.33   3.11   \n",
       "1      2009-01-01 00:20:00   996.57 -8.41  265.01 -9.28  93.40   3.23   3.02   \n",
       "2      2009-01-01 00:30:00   996.53 -8.51  264.91 -9.31  93.90   3.21   3.01   \n",
       "3      2009-01-01 00:40:00   996.51 -8.31  265.12 -9.07  94.20   3.26   3.07   \n",
       "4      2009-01-01 00:50:00   996.51 -8.27  265.15 -9.04  94.10   3.27   3.08   \n",
       "...                    ...      ...   ...     ...   ...    ...    ...    ...   \n",
       "420446 2016-12-31 23:20:00  1000.07 -4.05  269.10 -8.13  73.10   4.52   3.30   \n",
       "420447 2016-12-31 23:30:00   999.93 -3.35  269.81 -8.06  69.71   4.77   3.32   \n",
       "420448 2016-12-31 23:40:00   999.82 -3.16  270.01 -8.21  67.91   4.84   3.28   \n",
       "420449 2016-12-31 23:50:00   999.81 -4.23  268.94 -8.53  71.80   4.46   3.20   \n",
       "420450 2017-01-01 00:00:00   999.82 -4.82  268.36 -8.42  75.70   4.27   3.23   \n",
       "\n",
       "        vpdef    sh  h2Oc      rho    wv  max_wv     wd  \n",
       "0        0.22  1.94  3.12  1307.75  1.03    1.75  152.3  \n",
       "1        0.21  1.89  3.03  1309.80  0.72    1.50  136.1  \n",
       "2        0.20  1.88  3.02  1310.24  0.19    0.63  171.6  \n",
       "3        0.19  1.92  3.08  1309.19  0.34    0.50  198.0  \n",
       "4        0.19  1.92  3.09  1309.00  0.32    0.63  214.3  \n",
       "...       ...   ...   ...      ...   ...     ...    ...  \n",
       "420446   1.22  2.06  3.30  1292.98  0.67    1.52  240.0  \n",
       "420447   1.44  2.07  3.32  1289.44  1.14    1.92  234.3  \n",
       "420448   1.55  2.05  3.28  1288.39  1.08    2.00  215.2  \n",
       "420449   1.26  1.99  3.20  1293.56  1.49    2.16  225.8  \n",
       "420450   1.04  2.01  3.23  1296.38  1.23    1.96  184.9  \n",
       "\n",
       "[420451 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "      <th>tpot</th>\n",
       "      <th>tdew</th>\n",
       "      <th>rh</th>\n",
       "      <th>vpmax</th>\n",
       "      <th>vpact</th>\n",
       "      <th>vpdef</th>\n",
       "      <th>sh</th>\n",
       "      <th>h2Oc</th>\n",
       "      <th>rho</th>\n",
       "      <th>wv</th>\n",
       "      <th>max_wv</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-01 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.30</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-01 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.40</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-01 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.90</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-01 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.20</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-01 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.10</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420446</th>\n",
       "      <td>2016-12-31 23:20:00</td>\n",
       "      <td>1000.07</td>\n",
       "      <td>-4.05</td>\n",
       "      <td>269.10</td>\n",
       "      <td>-8.13</td>\n",
       "      <td>73.10</td>\n",
       "      <td>4.52</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.22</td>\n",
       "      <td>2.06</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1292.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.52</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420447</th>\n",
       "      <td>2016-12-31 23:30:00</td>\n",
       "      <td>999.93</td>\n",
       "      <td>-3.35</td>\n",
       "      <td>269.81</td>\n",
       "      <td>-8.06</td>\n",
       "      <td>69.71</td>\n",
       "      <td>4.77</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.07</td>\n",
       "      <td>3.32</td>\n",
       "      <td>1289.44</td>\n",
       "      <td>1.14</td>\n",
       "      <td>1.92</td>\n",
       "      <td>234.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420448</th>\n",
       "      <td>2016-12-31 23:40:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-3.16</td>\n",
       "      <td>270.01</td>\n",
       "      <td>-8.21</td>\n",
       "      <td>67.91</td>\n",
       "      <td>4.84</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.05</td>\n",
       "      <td>3.28</td>\n",
       "      <td>1288.39</td>\n",
       "      <td>1.08</td>\n",
       "      <td>2.00</td>\n",
       "      <td>215.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420449</th>\n",
       "      <td>2016-12-31 23:50:00</td>\n",
       "      <td>999.81</td>\n",
       "      <td>-4.23</td>\n",
       "      <td>268.94</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>71.80</td>\n",
       "      <td>4.46</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.99</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1293.56</td>\n",
       "      <td>1.49</td>\n",
       "      <td>2.16</td>\n",
       "      <td>225.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420450</th>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>999.82</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>268.36</td>\n",
       "      <td>-8.42</td>\n",
       "      <td>75.70</td>\n",
       "      <td>4.27</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.01</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1296.38</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>184.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420451 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Analyze the data\n",
    "\n",
    "We want to know what are the main patterns in order to correctly analyze the coherence of our model's predictions"
   ],
   "id": "40dcb53d7fe2b2e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General purpose plots: get an insight of global tendencies over years",
   "id": "9014f77911aa0252"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "colors = [\n",
    "    \"blue\",\n",
    "    \"orange\",\n",
    "    \"green\",\n",
    "    \"red\",\n",
    "    \"purple\",\n",
    "    \"brown\",\n",
    "    \"pink\",\n",
    "    \"gray\",\n",
    "    \"olive\",\n",
    "    \"cyan\",\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=nb_cols // 3, sharex=True, figsize=[10 * 3, 6 * nb_cols // 3])\n",
    "\n",
    "for i, col in enumerate(jena_climate_2009_2016.columns):\n",
    "    if col == \"datetime\":\n",
    "        continue\n",
    "    ax = axes[i // 3, i % 3]\n",
    "        \n",
    "    jena_climate_2009_2016.plot(x='datetime', y=col, ax=ax, label=columns[col], color=colors[i % (len(colors))])\n",
    "    \n",
    "    ax.grid(True)\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel(columns[col])\n",
    "    \n",
    "fig.tight_layout()"
   ],
   "id": "78b25b91f0385f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Link between temperature, pressure and humidity over a year",
   "id": "1e8fca40afa2ea7d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Observing the variation at some day\n",
    "reference = 2 * nb_rows / 5\n",
    "nb_days = 31 * 3\n",
    "\n",
    "start = int(reference)\n",
    "end = int(6 * 24 * nb_days + reference) \n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(8, 6 * 3), sharex=True)\n",
    "\n",
    "for i, col in enumerate(['t', 'p', 'rh']):\n",
    "    jena_climate_2009_2016.iloc[start:end].plot(x='datetime', label=columns[col], y=col, ax=axes[i])\n",
    "\n",
    "fig.tight_layout()"
   ],
   "id": "55e85b66c38f74ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Prepare data for the pipeline\n",
    "\n",
    "Be careful to remove the temperature from the dataset, as it's what we want to predict...\n",
    "\n",
    "We also don't consider the datetime column, as we can totally rely solely on indexes"
   ],
   "id": "3ead67f0e519cc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the dataset",
   "id": "502f0a159c8e65ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:41.202613Z",
     "start_time": "2024-08-12T13:22:41.043022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_proportion = 0.5\n",
    "validation_proportion = 0.25\n",
    "test_split = 1 - training_proportion - validation_proportion\n",
    "\n",
    "training_index = int(training_proportion * nb_rows)\n",
    "validation_index = training_index + int(validation_proportion * nb_rows)\n",
    "\n",
    "raw_data = jena_climate_2009_2016.copy()\n",
    "temperature = raw_data.t\n",
    "raw_data.pop('datetime')"
   ],
   "id": "a6dcdf45a1bb835",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2009-01-01 00:10:00\n",
       "1        2009-01-01 00:20:00\n",
       "2        2009-01-01 00:30:00\n",
       "3        2009-01-01 00:40:00\n",
       "4        2009-01-01 00:50:00\n",
       "                 ...        \n",
       "420446   2016-12-31 23:20:00\n",
       "420447   2016-12-31 23:30:00\n",
       "420448   2016-12-31 23:40:00\n",
       "420449   2016-12-31 23:50:00\n",
       "420450   2017-01-01 00:00:00\n",
       "Name: datetime, Length: 420451, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Normalizing all the data\n",
    "\n",
    "We normalize all the values (they're all numerical, it's easy) according to the mean and standard deviation of the training data."
   ],
   "id": "84c44c81cc4abf04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:42.605089Z",
     "start_time": "2024-08-12T13:22:42.364981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = raw_data[:training_index].mean()\n",
    "std = raw_data[:training_index].std()\n",
    "raw_data = (raw_data - mean) / std\n",
    "raw_data[:training_index]"
   ],
   "id": "bb6fb8ef75398978",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               p         t      tpot      tdew        rh     vpmax     vpact  \\\n",
       "0       0.913649 -1.920636 -1.974488 -1.866254  1.048015 -1.291316 -1.467152   \n",
       "1       0.919528 -1.965100 -2.018478 -1.919925  1.054028 -1.304472 -1.488855   \n",
       "2       0.914825 -1.976501 -2.029758 -1.924162  1.084097 -1.307103 -1.491266   \n",
       "3       0.912474 -1.953699 -2.006071 -1.890265  1.102138 -1.300525 -1.476798   \n",
       "4       0.912474 -1.949139 -2.002687 -1.886027  1.096124 -1.299210 -1.474386   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "210220 -0.199796 -0.171691 -0.155101 -0.427015 -0.628593 -0.380947 -0.599035   \n",
       "210221 -0.183336 -0.148889 -0.133670 -0.421365 -0.668884 -0.362529 -0.594212   \n",
       "210222 -0.172754 -0.144328 -0.130287 -0.418540 -0.676101 -0.358583 -0.594212   \n",
       "210223 -0.163348 -0.153449 -0.140438 -0.412891 -0.643627 -0.366476 -0.589389   \n",
       "210224 -0.166875 -0.173971 -0.160741 -0.410066 -0.587700 -0.382263 -0.584566   \n",
       "\n",
       "           vpdef        sh      h2Oc       rho        wv    max_wv        wd  \n",
       "0      -0.782343 -1.470122 -1.472032  2.124151 -0.730165 -0.779351 -0.281192  \n",
       "1      -0.784440 -1.489114 -1.493462  2.172914 -0.932305 -0.886968 -0.469893  \n",
       "2      -0.786537 -1.492912 -1.495843  2.183381 -1.277899 -1.261473 -0.056383  \n",
       "3      -0.788633 -1.477719 -1.481556  2.158404 -1.180089 -1.317434  0.251128  \n",
       "4      -0.788633 -1.477719 -1.479175  2.153885 -1.193130 -1.261473  0.440993  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "210220 -0.086271 -0.596521 -0.598159  0.102950  1.617266  1.398809  0.181239  \n",
       "210221 -0.061112 -0.592722 -0.591016  0.086299  1.930257  1.708745  0.427015  \n",
       "210222 -0.054822 -0.592722 -0.591016  0.084634  1.695513  1.329935  0.258117  \n",
       "210223 -0.071595 -0.585126 -0.586254  0.095100  1.506415  1.054436  0.117174  \n",
       "210224 -0.100948 -0.585126 -0.583873  0.112703  1.206465  1.071655  0.019330  \n",
       "\n",
       "[210225 rows x 14 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>t</th>\n",
       "      <th>tpot</th>\n",
       "      <th>tdew</th>\n",
       "      <th>rh</th>\n",
       "      <th>vpmax</th>\n",
       "      <th>vpact</th>\n",
       "      <th>vpdef</th>\n",
       "      <th>sh</th>\n",
       "      <th>h2Oc</th>\n",
       "      <th>rho</th>\n",
       "      <th>wv</th>\n",
       "      <th>max_wv</th>\n",
       "      <th>wd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913649</td>\n",
       "      <td>-1.920636</td>\n",
       "      <td>-1.974488</td>\n",
       "      <td>-1.866254</td>\n",
       "      <td>1.048015</td>\n",
       "      <td>-1.291316</td>\n",
       "      <td>-1.467152</td>\n",
       "      <td>-0.782343</td>\n",
       "      <td>-1.470122</td>\n",
       "      <td>-1.472032</td>\n",
       "      <td>2.124151</td>\n",
       "      <td>-0.730165</td>\n",
       "      <td>-0.779351</td>\n",
       "      <td>-0.281192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.919528</td>\n",
       "      <td>-1.965100</td>\n",
       "      <td>-2.018478</td>\n",
       "      <td>-1.919925</td>\n",
       "      <td>1.054028</td>\n",
       "      <td>-1.304472</td>\n",
       "      <td>-1.488855</td>\n",
       "      <td>-0.784440</td>\n",
       "      <td>-1.489114</td>\n",
       "      <td>-1.493462</td>\n",
       "      <td>2.172914</td>\n",
       "      <td>-0.932305</td>\n",
       "      <td>-0.886968</td>\n",
       "      <td>-0.469893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914825</td>\n",
       "      <td>-1.976501</td>\n",
       "      <td>-2.029758</td>\n",
       "      <td>-1.924162</td>\n",
       "      <td>1.084097</td>\n",
       "      <td>-1.307103</td>\n",
       "      <td>-1.491266</td>\n",
       "      <td>-0.786537</td>\n",
       "      <td>-1.492912</td>\n",
       "      <td>-1.495843</td>\n",
       "      <td>2.183381</td>\n",
       "      <td>-1.277899</td>\n",
       "      <td>-1.261473</td>\n",
       "      <td>-0.056383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.912474</td>\n",
       "      <td>-1.953699</td>\n",
       "      <td>-2.006071</td>\n",
       "      <td>-1.890265</td>\n",
       "      <td>1.102138</td>\n",
       "      <td>-1.300525</td>\n",
       "      <td>-1.476798</td>\n",
       "      <td>-0.788633</td>\n",
       "      <td>-1.477719</td>\n",
       "      <td>-1.481556</td>\n",
       "      <td>2.158404</td>\n",
       "      <td>-1.180089</td>\n",
       "      <td>-1.317434</td>\n",
       "      <td>0.251128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.912474</td>\n",
       "      <td>-1.949139</td>\n",
       "      <td>-2.002687</td>\n",
       "      <td>-1.886027</td>\n",
       "      <td>1.096124</td>\n",
       "      <td>-1.299210</td>\n",
       "      <td>-1.474386</td>\n",
       "      <td>-0.788633</td>\n",
       "      <td>-1.477719</td>\n",
       "      <td>-1.479175</td>\n",
       "      <td>2.153885</td>\n",
       "      <td>-1.193130</td>\n",
       "      <td>-1.261473</td>\n",
       "      <td>0.440993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210220</th>\n",
       "      <td>-0.199796</td>\n",
       "      <td>-0.171691</td>\n",
       "      <td>-0.155101</td>\n",
       "      <td>-0.427015</td>\n",
       "      <td>-0.628593</td>\n",
       "      <td>-0.380947</td>\n",
       "      <td>-0.599035</td>\n",
       "      <td>-0.086271</td>\n",
       "      <td>-0.596521</td>\n",
       "      <td>-0.598159</td>\n",
       "      <td>0.102950</td>\n",
       "      <td>1.617266</td>\n",
       "      <td>1.398809</td>\n",
       "      <td>0.181239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210221</th>\n",
       "      <td>-0.183336</td>\n",
       "      <td>-0.148889</td>\n",
       "      <td>-0.133670</td>\n",
       "      <td>-0.421365</td>\n",
       "      <td>-0.668884</td>\n",
       "      <td>-0.362529</td>\n",
       "      <td>-0.594212</td>\n",
       "      <td>-0.061112</td>\n",
       "      <td>-0.592722</td>\n",
       "      <td>-0.591016</td>\n",
       "      <td>0.086299</td>\n",
       "      <td>1.930257</td>\n",
       "      <td>1.708745</td>\n",
       "      <td>0.427015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210222</th>\n",
       "      <td>-0.172754</td>\n",
       "      <td>-0.144328</td>\n",
       "      <td>-0.130287</td>\n",
       "      <td>-0.418540</td>\n",
       "      <td>-0.676101</td>\n",
       "      <td>-0.358583</td>\n",
       "      <td>-0.594212</td>\n",
       "      <td>-0.054822</td>\n",
       "      <td>-0.592722</td>\n",
       "      <td>-0.591016</td>\n",
       "      <td>0.084634</td>\n",
       "      <td>1.695513</td>\n",
       "      <td>1.329935</td>\n",
       "      <td>0.258117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210223</th>\n",
       "      <td>-0.163348</td>\n",
       "      <td>-0.153449</td>\n",
       "      <td>-0.140438</td>\n",
       "      <td>-0.412891</td>\n",
       "      <td>-0.643627</td>\n",
       "      <td>-0.366476</td>\n",
       "      <td>-0.589389</td>\n",
       "      <td>-0.071595</td>\n",
       "      <td>-0.585126</td>\n",
       "      <td>-0.586254</td>\n",
       "      <td>0.095100</td>\n",
       "      <td>1.506415</td>\n",
       "      <td>1.054436</td>\n",
       "      <td>0.117174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210224</th>\n",
       "      <td>-0.166875</td>\n",
       "      <td>-0.173971</td>\n",
       "      <td>-0.160741</td>\n",
       "      <td>-0.410066</td>\n",
       "      <td>-0.587700</td>\n",
       "      <td>-0.382263</td>\n",
       "      <td>-0.584566</td>\n",
       "      <td>-0.100948</td>\n",
       "      <td>-0.585126</td>\n",
       "      <td>-0.583873</td>\n",
       "      <td>0.112703</td>\n",
       "      <td>1.206465</td>\n",
       "      <td>1.071655</td>\n",
       "      <td>0.019330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210225 rows × 14 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Creating a temporal sliding window\n",
    "\n",
    "As stated in the book, we'll use the past five days to predict a temperature 24 hours in the future.\n",
    "\n",
    "We only want one point per hour in the future, so we skip 6 timesteps (of 10 minutes each)\n",
    "\n",
    "The datasets will now contain :\n",
    "- A samples matrix, of shape (samples, timesteps, features)\n",
    "- A predictions vector with the temperatures corresponding to each sample"
   ],
   "id": "3ed1c0993c8dc275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:44.337322Z",
     "start_time": "2024-08-12T13:22:43.982805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sampling_rate = 6  # Each input and output point will be taken every 6 timesteps (one per hour)\n",
    "sequence_length = 24 * 5\n",
    "delay = sampling_rate * (sequence_length + 24 - 1)  # Delay to start target values, in number of timesteps ; TODO: understand the -1\n",
    "batch_size = 256\n",
    "\n",
    "timeseries_kwargs = {\n",
    "    'data': raw_data[:-delay], # Don't include the last sequence\n",
    "    'targets': temperature[delay:],\n",
    "    'sampling_rate': sampling_rate,\n",
    "    'sequence_length': sequence_length,\n",
    "    'batch_size': batch_size, # Shuffle the samples between them, not inside a sample of course\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "train_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    end_index=training_index,\n",
    ")\n",
    "\n",
    "val_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    start_index=training_index,  # Start and end index are also applied to targets\n",
    "    end_index=validation_index,\n",
    ")\n",
    "\n",
    "test_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **timeseries_kwargs,\n",
    "    start_index=validation_index,\n",
    ")"
   ],
   "id": "70e2848c3b4e426a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Test different models\n",
    "\n",
    "In this part, we will dive into many models, starting from the most naïve one to the most complex, in order to evaluate the gains of each one versus its computation time"
   ],
   "id": "cbec9452109d2ea4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Skeleton\n",
    "\n",
    "We first define some helper functions to compile, fit and save our models:"
   ],
   "id": "32323ae02fe12acf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T13:22:47.633581Z",
     "start_time": "2024-08-12T13:22:47.624499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compile_model(\n",
    "        model,\n",
    "        learning_rate=1e-3,\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=None):\n",
    "\n",
    "    if metrics is None:\n",
    "        metrics = []\n",
    "\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "\n",
    "def train_model(model,\n",
    "                training_data,\n",
    "                epochs=100,\n",
    "                callbacks=None,\n",
    "                early_stopping=None,\n",
    "                validation_split=0.2,\n",
    "                validation_data=None,\n",
    "                name='model',\n",
    "                log_dir='logs/fit'\n",
    "                ):\n",
    "\n",
    "    if callbacks is None:\n",
    "        callbacks = []\n",
    "        \n",
    "    if early_stopping is not None:\n",
    "        callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='loss', patience=early_stopping))\n",
    "\n",
    "    date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(f'models/{name}.keras', save_best_only=True))\n",
    "    callbacks.append(tf.keras.callbacks.BackupAndRestore(backup_dir=f'/tmp/backup/{name}--{date}'))\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(log_dir=f'{log_dir}/{name}--{date}', histogram_freq=1))\n",
    "        \n",
    "    # We don't have \"batch size\" here as the batches were already made during data preparation\n",
    "    kwargs = {\n",
    "        'epochs': epochs,\n",
    "        'callbacks': callbacks,\n",
    "    }\n",
    "    if validation_data is not None:\n",
    "        kwargs['validation_data'] = validation_data\n",
    "    else:\n",
    "        kwargs['validation_split'] = validation_split\n",
    "\n",
    "    model.fit(\n",
    "        training_data,\n",
    "        **kwargs\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "\n",
    "def create_and_process_model(name, build_function, training_data=train_data, learning_rate=1e-3):\n",
    "    model = build_function()\n",
    "    # For the loss, we use MSE as it's more stable around 0 (for gradient calculation)\n",
    "    # But for evaluation, we prefer using MAE which is clearly interpretable as an error on average\n",
    "    compile_model(\n",
    "        model, \n",
    "        learning_rate=learning_rate,\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    train_model(\n",
    "        model,\n",
    "        training_data,\n",
    "        epochs=100,\n",
    "        validation_data=val_data,\n",
    "        name=name\n",
    "    )\n",
    "    \n",
    "    \n",
    "def test_best_model(name):\n",
    "    best_model = tf.keras.models.load_model(f'models/{name}.keras')\n",
    "    print(f'MAE for {name}: {best_model.evaluate(test_data)[1]:.2f}')"
   ],
   "id": "f97215381dba70cd",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Baseline\n",
    "\n",
    "We must then create a more robust model that performs better on the same metrics.\n",
    "\n",
    "The baseline approach consists of translating the temperature 24 hours to the future and use them as predictions. So in our samples, we use the last temperature measures (to be exactly 24 hours apart from the prediction).\n",
    "\n",
    "We use the Mean Absolute Error (MSE) metric, i.e. sum(|prediction - target|) / nb_samples"
   ],
   "id": "60db64d6d0ecaf97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_baseline_method(dataset):\n",
    "    total_absolute_error = 0.0\n",
    "    nb_samples = 0\n",
    "    for samples, targets in dataset:\n",
    "        # We want all the samples of the batch, the last timestep, and the temperature column\n",
    "        # Be careful: we didn't normalize the targets (temperature array), so we have to de-normalize the prediction\n",
    "        predictions = samples[:, -1, 1] * std.t + mean.t\n",
    "        total_absolute_error += np.sum(np.abs(predictions - targets))\n",
    "        nb_samples += samples.shape[0]  # Reflex: use the shape instead of far variables or hard-coded values\n",
    "    return total_absolute_error / nb_samples\n",
    "        \n",
    "print(f\"Validation MSE (in °C): {evaluate_baseline_method(val_data):.3f}\")\n",
    "print(f\"Test MSE (in °C): {evaluate_baseline_method(test_data):.3f}\")"
   ],
   "id": "99376a7a3eac69a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that by using our baseline method, our predictions would be off by around two and a half degrees in average. This is not bad, but it can definitely be improved.",
   "id": "2d7e4dd8acac8517"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Dense\n",
    "\n",
    "Note: we don't use an activation function for the last layer, as we are facing a regression problem."
   ],
   "id": "5b140b0de17ca5f6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_dense():\n",
    "    # raw_data.shape[1:] skips the number of features to just get the shape of the input\n",
    "    # In this special case, we could replace it by \"nb_columns\"\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    # Our network must deal with vectors, i.e. one-dimensional tensors ; so we flatten the input data\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "create_and_process_model('dense', create_dense)"
   ],
   "id": "22284f08acf44009",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('dense')",
   "id": "3ed35d0d1337061e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can see that this model didn't really achieve a good performance compared to the baseline method. We have to seek for a more complex model.\n",
    "\n",
    "One of the reasons is the flattening : we remove the temporal information from the data, whereas this is crucial for our forecasting task."
   ],
   "id": "fef82c1a8fe4309c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1D-convolutional network\n",
    "\n",
    "The 1D convolution is well suited for timeseries (temporal convolution)."
   ],
   "id": "9daa6ac97aa69489"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_convolutional():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    # Our network must deal with vectors, i.e. one-dimensional tensors ; so we flatten the input data\n",
    "    x = tf.keras.layers.Flatten()(inputs)\n",
    "    # We use convolution windows of 24 hours, as most of the patterns would be detected there\n",
    "    # in accordance to the relative continuity and periodicity of the parameters\n",
    "    # TODO: understand the consequence of \"padding='causal'\"\n",
    "    x = tf.keras.layers.Conv1D(8, 24, padding='causal', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool1D(2)(x)\n",
    "    # Don't forget to adapt the window size as we downsample\n",
    "    # = the model learns to detect more precise patterns\n",
    "    x = tf.keras.layers.Conv1D(8, 12, padding='causal', activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPool1D(2)(x)\n",
    "    x = tf.keras.layers.Conv1D(8, 6, padding='causal', activation='relu')(x)\n",
    "    # TODO: understand why we finish with a global average pooling\n",
    "    x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "create_and_process_model('convolutional', create_convolutional)"
   ],
   "id": "6efcda0ed857e574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('convolutional')",
   "id": "392a5ab54b44d159",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model performs worse than the densely-connected one. This is simply caused by the convolution itself, that treats segments of data the same way, but the weather contains variations over days and months.",
   "id": "2ef073ebd0cb863d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### First look at RNNs\n",
    "\n",
    "RNNs are better suited to forecast some data, as they intrinsically work with timesteps / a notion of order, which is crucial here."
   ],
   "id": "ece2f9c7d1b5a213"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_simplernn():\n",
    "    # The SimpleRNN layer can process sequences of arbitrary length\n",
    "    inputs = tf.keras.Input(shape=(None, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.SimpleRNN(16)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('simple_rnn', create_simplernn)\n"
   ],
   "id": "31570c532f1a2187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('simple_rnn')",
   "id": "64b4241efc710561",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "That's better than the baseline approach, meaning that machine learning has a real added value",
   "id": "645d8d46e6bd04c6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Long Short-Term Memory (LSTM)",
   "id": "1c83955dd9a935db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_lstm():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(16)(inputs)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('lstm', create_lstm)"
   ],
   "id": "32daedf96a609b2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('lstm')",
   "id": "233be17a249aced2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's quite a good model, but there is a big problem: if we look at the loss and MAE graphs, we see that training metrics always decrease, whereas validation ones start to increase. Both are diverging rapidly: the model is overfitting!",
   "id": "cb0d99e74c8ef289"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Adding recurrent dropout\n",
    "\n",
    "We can now increase the number of units in the LSTM layer, as the dropout will prevent a quick overfitting in the other case.\n",
    "\n",
    "We also add a Dropout layer as usual to finally regularize the output of the LSTM layer."
   ],
   "id": "a23e03687ce97355"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_lstm_dropout():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(32, recurrent_dropout=0.25)(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('lstm_dropout', create_lstm_dropout)"
   ],
   "id": "d05f9d0afedfa9f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('lstm_dropout')",
   "id": "d16ff26d9f64528d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Scaling our model",
   "id": "ed78b0757c6dc033"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_gru():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.GRU(32, recurrent_dropout=0.5)(inputs)\n",
    "    #x = tf.keras.layers.GRU(32, recurrent_dropout=0.5)(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('gru', create_gru)"
   ],
   "id": "d4ac4f525aedcba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('gru')",
   "id": "30d38cba88ff5323",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Reversed-order RNN\n",
    "\n",
    "Before moving on, let's test the influence of reversing the input sequence, to see if the chronological order really matters."
   ],
   "id": "e18c1b86c064a51e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "reversed_timeseries_kwargs = {\n",
    "    'data': raw_data[:-delay][::-1], # Don't include the last sequence\n",
    "    'targets': temperature[delay:][::-1],\n",
    "    'sampling_rate': sampling_rate,\n",
    "    'sequence_length': sequence_length,\n",
    "    'batch_size': batch_size, # Shuffle the samples between them, not inside a sample of course\n",
    "    'shuffle': True,\n",
    "}\n",
    "\n",
    "reversed_train_data = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    **reversed_timeseries_kwargs,\n",
    "    end_index=training_index,\n",
    ")"
   ],
   "id": "ee89cfdc09154161",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "create_and_process_model('reversed_lstm', create_lstm, training_data=reversed_train_data)",
   "id": "1b71d55d21a98d25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('reversed_lstm')",
   "id": "d37d83dfd5be7a77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It's not really convincing as-is: indeed, the predictions are more tied to most recent weather conditions than past ones.\n",
    "\n",
    "The anti-chronological order could still provide valuable information if we combine it to the chronological order."
   ],
   "id": "aeb2bb59acf8dc8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Bidirectional RNN",
   "id": "7a3db06c087471c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_bidirectional():\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, recurrent_dropout=0.5))(inputs)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "create_and_process_model('bidirectional', create_bidirectional)"
   ],
   "id": "10f889e7b3115a3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_best_model('bidirectional')",
   "id": "17989e4246a733d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- This model is more complex, thus overfitting earlier\n",
    "- The anti-chronological information is poluting the chronological one here: the past is way less important than the recent for this task"
   ],
   "id": "dd76a387e931f9ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "We can't really achieve better performance than the baseline: we only have weather data at one point, however conditions are clearly influenced by other places.\n",
    "\n",
    "Machine learning still is relevant to predict a future where the past contains information and can influence the rest."
   ],
   "id": "697dcc30b0cb90f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The final model\n",
    "\n",
    "We will first seek for the best hyperparameters, by using KerasTuner."
   ],
   "id": "4c315dfad2a813f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:15:49.515688Z",
     "start_time": "2024-08-12T19:15:49.496580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_final(\n",
    "        recurrent_dropout=0.6,\n",
    "        units=32,\n",
    "        l2_units=None,\n",
    "        end_neural=True\n",
    "    ):\n",
    "    inputs = tf.keras.Input(shape=(sequence_length, raw_data.shape[-1]))\n",
    "    x = tf.keras.layers.LSTM(units=units, recurrent_dropout=recurrent_dropout)(inputs)\n",
    "\n",
    "    if l2_units is not None:\n",
    "       x = tf.keras.layers.LSTM(units=l2_units, recurrent_dropout=recurrent_dropout)(inputs)\n",
    "\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    \n",
    "    if end_neural:\n",
    "        x = tf.keras.layers.Dense(16)(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(1)(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "def search_final(hp):\n",
    "    model = create_final(\n",
    "        recurrent_dropout=hp.Float('recurrent_dropout', min_value=0.2, max_value=0.7, default=0.5, step=0.1),\n",
    "        units=hp.Int('units', min_value=32, max_value=64, step=32),\n",
    "        l2_units=hp.Int('units', min_value=32, max_value=64, step=32),\n",
    "        end_neural=hp.Boolean('end_neural'),\n",
    "    )\n",
    "    learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model"
   ],
   "id": "2dc93e8b4e34a1d4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tuner = keras_tuner.Hyperband(\n",
    "    hypermodel=create_final,\n",
    "    objective='val_mae',\n",
    "    max_epochs=15,\n",
    "    overwrite=True,\n",
    "    directory='model_search',\n",
    "    project_name='weather_forecasting'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()\n",
    "\n",
    "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=f'logs/fit/final--{date}', histogram_freq=1)\n",
    "]\n",
    "\n",
    "tuner.search(train_data, validation_data=val_data, callbacks=callbacks)\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ],
   "id": "64779fe0efbe5eca",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 47 Complete [00h 06m 20s]\n",
      "val_mae: 2.3841261863708496\n",
      "\n",
      "Best val_mae So Far: 2.2665553092956543\n",
      "Total elapsed time: 04h 27m 13s\n",
      "\n",
      "Search: Running Trial #48\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.4               |0.6               |recurrent_dropout\n",
      "64                |32                |units\n",
      "True              |False             |l2\n",
      "True              |True              |end_neural\n",
      "0.00049269        |0.0045213         |learning_rate\n",
      "6                 |6                 |tuner/epochs\n",
      "0                 |2                 |tuner/initial_epoch\n",
      "2                 |3                 |tuner/bracket\n",
      "0                 |1                 |tuner/round\n",
      "\n",
      "Epoch 1/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 168ms/step - loss: 38.0526 - mae: 4.5436 - val_loss: 9.2990 - val_mae: 2.3805\n",
      "Epoch 2/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m136s\u001B[0m 166ms/step - loss: 15.3070 - mae: 3.0477 - val_loss: 9.1808 - val_mae: 2.3557\n",
      "Epoch 3/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m137s\u001B[0m 167ms/step - loss: 14.4910 - mae: 2.9561 - val_loss: 9.0417 - val_mae: 2.3349\n",
      "Epoch 4/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m135s\u001B[0m 165ms/step - loss: 14.1422 - mae: 2.9228 - val_loss: 8.8647 - val_mae: 2.3100\n",
      "Epoch 5/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m139s\u001B[0m 170ms/step - loss: 13.7686 - mae: 2.8805 - val_loss: 8.8248 - val_mae: 2.3057\n",
      "Epoch 6/6\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 184ms/step - loss: 13.5495 - mae: 2.8589"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 8\u001B[0m\n\u001B[1;32m      1\u001B[0m date \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mdatetime\u001B[38;5;241m.\u001B[39mnow()\u001B[38;5;241m.\u001B[39mstrftime(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mH\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mM\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mS\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      3\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      4\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mloss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m),\n\u001B[1;32m      5\u001B[0m     tf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mTensorBoard(log_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogs/fit/final--\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdate\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, histogram_freq\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      6\u001B[0m ]\n\u001B[0;32m----> 8\u001B[0m \u001B[43mtuner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msearch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m best_hps \u001B[38;5;241m=\u001B[39m tuner\u001B[38;5;241m.\u001B[39mget_best_hyperparameters(num_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:234\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[0;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    233\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m--> 234\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_end(trial)\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:274\u001B[0m, in \u001B[0;36mBaseTuner._try_run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[1;32m    273\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 274\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_and_update_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m         trial\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m=\u001B[39m trial_module\u001B[38;5;241m.\u001B[39mTrialStatus\u001B[38;5;241m.\u001B[39mCOMPLETED\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/base_tuner.py:239\u001B[0m, in \u001B[0;36mBaseTuner._run_and_update_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_and_update_trial\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs):\n\u001B[0;32m--> 239\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    240\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_trial(trial\u001B[38;5;241m.\u001B[39mtrial_id)\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mexists(\n\u001B[1;32m    241\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mobjective\u001B[38;5;241m.\u001B[39mname\n\u001B[1;32m    242\u001B[0m     ):\n\u001B[1;32m    243\u001B[0m         \u001B[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001B[39;00m\n\u001B[1;32m    244\u001B[0m         \u001B[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001B[39;00m\n\u001B[1;32m    245\u001B[0m         \u001B[38;5;66;03m# use case. No further action needed in this case.\u001B[39;00m\n\u001B[1;32m    246\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    247\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe use case of calling \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    248\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    254\u001B[0m             stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m    255\u001B[0m         )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/tuners/hyperband.py:427\u001B[0m, in \u001B[0;36mHyperband.run_trial\u001B[0;34m(self, trial, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[1;32m    425\u001B[0m     fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepochs\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtuner/epochs\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    426\u001B[0m     fit_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minitial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m hp\u001B[38;5;241m.\u001B[39mvalues[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtuner/initial_epoch\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 427\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_kwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:314\u001B[0m, in \u001B[0;36mTuner.run_trial\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    312\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(model_checkpoint)\n\u001B[1;32m    313\u001B[0m     copied_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcallbacks\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m callbacks\n\u001B[0;32m--> 314\u001B[0m     obj_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_and_fit_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcopied_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    316\u001B[0m     histories\u001B[38;5;241m.\u001B[39mappend(obj_value)\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m histories\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/tuner.py:233\u001B[0m, in \u001B[0;36mTuner._build_and_fit_model\u001B[0;34m(self, trial, *args, **kwargs)\u001B[0m\n\u001B[1;32m    231\u001B[0m hp \u001B[38;5;241m=\u001B[39m trial\u001B[38;5;241m.\u001B[39mhyperparameters\n\u001B[1;32m    232\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[0;32m--> 233\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhypermodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;66;03m# Save the build config for model loading later.\u001B[39;00m\n\u001B[1;32m    236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m backend\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mmulti_backend():\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001B[0m, in \u001B[0;36mHyperModel.fit\u001B[0;34m(self, hp, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, hp, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    126\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Train the model.\u001B[39;00m\n\u001B[1;32m    127\u001B[0m \n\u001B[1;32m    128\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m        If return a float, it should be the `objective` value.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 149\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:343\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_epoch_iterator\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    333\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_epoch_iterator \u001B[38;5;241m=\u001B[39m TFEpochIterator(\n\u001B[1;32m    334\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m    335\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    341\u001B[0m         shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    342\u001B[0m     )\n\u001B[0;32m--> 343\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    344\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    345\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    346\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    347\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    352\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    355\u001B[0m }\n\u001B[1;32m    356\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:429\u001B[0m, in \u001B[0;36mTensorFlowTrainer.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    428\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m--> 429\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    430\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    431\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_end(step, logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1567\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Trial 47 Complete [00h 06m 20s]\n",
    "\n",
    "val_mae: 2.3841261863708496\n",
    "\n",
    "\n",
    "Best val_mae So Far: 2.2665553092956543\n",
    "\n",
    "Total elapsed time: 04h 27m 13s\n",
    "\n",
    "\n",
    "Search: Running Trial #48\n",
    "\n",
    "\n",
    "| Value      | Best Value So Far | Hyperparameter      |\n",
    "|------------|-------------------|---------------------|\n",
    "| 0.4        | 0.6               | recurrent_dropout   |\n",
    "| 64         | 32                | units               |\n",
    "| True       | False             | l2                  |\n",
    "| True       | True              | end_neural          |\n",
    "| 0.00049269 | 0.0045213         | learning_rate       |\n",
    "| 6          | 6                 | tuner/epochs        |\n",
    "| 0          | 2                 | tuner/initial_epoch |\n",
    "| 2          | 3                 | tuner/bracket       |\n",
    "| 0          | 1                 | tuner/round         |\n",
    "\n",
    "We can now use these parameters to create our model."
   ],
   "id": "84b27a8551991150"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:47:30.872028Z",
     "start_time": "2024-08-12T19:15:53.649498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_model = create_final(\n",
    "    recurrent_dropout=0.6,\n",
    "    units=32,\n",
    "    l2_units=None,\n",
    "    end_neural=True\n",
    ")\n",
    "\n",
    "compile_model(\n",
    "    final_model, \n",
    "    learning_rate=45e-4,\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=['mae']\n",
    ")\n",
    "print(final_model.summary())\n",
    "train_model(\n",
    "    final_model,\n",
    "    train_data,\n",
    "    epochs=100,\n",
    "    validation_data=val_data,\n",
    "    name='final'\n",
    ")"
   ],
   "id": "e1af7b3031a3961b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m120\u001B[0m, \u001B[38;5;34m14\u001B[0m)        │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │         \u001B[38;5;34m6,016\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │           \u001B[38;5;34m528\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m)             │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │            \u001B[38;5;34m17\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m6,561\u001B[0m (25.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,561</span> (25.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m6,561\u001B[0m (25.63 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,561</span> (25.63 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m96s\u001B[0m 114ms/step - loss: 23.2959 - mae: 3.6314 - val_loss: 9.2714 - val_mae: 2.3586\n",
      "Epoch 2/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m102s\u001B[0m 124ms/step - loss: 14.9055 - mae: 2.9945 - val_loss: 10.0066 - val_mae: 2.4470\n",
      "Epoch 3/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m124s\u001B[0m 103ms/step - loss: 14.1885 - mae: 2.9214 - val_loss: 8.9559 - val_mae: 2.3192\n",
      "Epoch 4/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m65s\u001B[0m 79ms/step - loss: 13.7758 - mae: 2.8852 - val_loss: 9.6568 - val_mae: 2.4123\n",
      "Epoch 5/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m143s\u001B[0m 154ms/step - loss: 13.4369 - mae: 2.8447 - val_loss: 9.0105 - val_mae: 2.3274\n",
      "Epoch 6/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m87s\u001B[0m 107ms/step - loss: 13.2315 - mae: 2.8274 - val_loss: 8.7945 - val_mae: 2.2894\n",
      "Epoch 7/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 76ms/step - loss: 13.1199 - mae: 2.8136 - val_loss: 8.7541 - val_mae: 2.2909\n",
      "Epoch 8/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m106s\u001B[0m 129ms/step - loss: 13.0002 - mae: 2.7981 - val_loss: 9.0692 - val_mae: 2.3297\n",
      "Epoch 9/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m87s\u001B[0m 107ms/step - loss: 12.9517 - mae: 2.7953 - val_loss: 9.1753 - val_mae: 2.3475\n",
      "Epoch 10/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m90s\u001B[0m 110ms/step - loss: 12.8448 - mae: 2.7837 - val_loss: 9.0116 - val_mae: 2.3189\n",
      "Epoch 11/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 91ms/step - loss: 12.7897 - mae: 2.7742 - val_loss: 8.7945 - val_mae: 2.2994\n",
      "Epoch 12/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m96s\u001B[0m 117ms/step - loss: 12.6584 - mae: 2.7643 - val_loss: 9.0947 - val_mae: 2.3399\n",
      "Epoch 13/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 137ms/step - loss: 12.6384 - mae: 2.7588 - val_loss: 9.1939 - val_mae: 2.3433\n",
      "Epoch 14/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m114s\u001B[0m 139ms/step - loss: 12.5869 - mae: 2.7528 - val_loss: 8.9332 - val_mae: 2.3035\n",
      "Epoch 15/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m145s\u001B[0m 142ms/step - loss: 12.4651 - mae: 2.7406 - val_loss: 9.1570 - val_mae: 2.3451\n",
      "Epoch 16/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m113s\u001B[0m 108ms/step - loss: 12.5049 - mae: 2.7453 - val_loss: 9.2063 - val_mae: 2.3393\n",
      "Epoch 17/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 96ms/step - loss: 12.4672 - mae: 2.7405 - val_loss: 10.1540 - val_mae: 2.4550\n",
      "Epoch 18/100\n",
      "\u001B[1m819/819\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m84s\u001B[0m 102ms/step - loss: 12.4398 - mae: 2.7390 - val_loss: 9.4688 - val_mae: 2.3696\n",
      "Epoch 19/100\n",
      "\u001B[1m564/819\u001B[0m \u001B[32m━━━━━━━━━━━━━\u001B[0m\u001B[37m━━━━━━━\u001B[0m \u001B[1m25s\u001B[0m 100ms/step - loss: 12.4493 - mae: 2.7344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[57], line 15\u001B[0m\n\u001B[1;32m      8\u001B[0m compile_model(\n\u001B[1;32m      9\u001B[0m     final_model, \n\u001B[1;32m     10\u001B[0m     learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m45e-4\u001B[39m,\n\u001B[1;32m     11\u001B[0m     loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mMeanSquaredError(),\n\u001B[1;32m     12\u001B[0m     metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmae\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     13\u001B[0m )\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(final_model\u001B[38;5;241m.\u001B[39msummary())\n\u001B[0;32m---> 15\u001B[0m \u001B[43mtrain_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfinal_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfinal\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m     21\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[50], line 47\u001B[0m, in \u001B[0;36mtrain_model\u001B[0;34m(model, training_data, epochs, callbacks, early_stopping, validation_split, validation_data, name, log_dir)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     45\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation_split\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m validation_split\n\u001B[0;32m---> 47\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    317\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 318\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    320\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(step, logs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1552\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1550\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1551\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1552\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1553\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1554\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1555\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1556\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1560\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1561\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1562\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1566\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1567\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T19:47:59.137045Z",
     "start_time": "2024-08-12T19:47:34.440609Z"
    }
   },
   "cell_type": "code",
   "source": "test_best_model('final')",
   "id": "edb1fdb23447e356",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m405/405\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m25s\u001B[0m 59ms/step - loss: 9.7388 - mae: 2.4380\n",
      "MAE for final: 2.44\n"
     ]
    }
   ],
   "execution_count": 58
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
