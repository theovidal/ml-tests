{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Translation using a Transformer",
   "id": "c2b62afd88608571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import datetime\n",
    "import string\n",
    "import re\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np"
   ],
   "id": "e0bc65595f64d136",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Loading data\n",
    "\n",
    "To use the data for translation purposes from English to Spanish, we must add [start] and [end] markers to all spanish sentences.\n",
    "\n",
    "We directly put all the sentences into a list of pairs to constitute a dataset."
   ],
   "id": "30a8cd8469108358"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ],
   "id": "2fe7b125d12643d4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "validation_split = 0.2\n",
    "\n",
    "text_pairs = []\n",
    "\n",
    "with open('spa-eng/spa.txt', 'r') as f:\n",
    "  for line in f.readlines():\n",
    "    eng, spa = line.strip('\\n').split('\t')\n",
    "    text_pairs.append((eng, '[start] ' + spa + ' [end]'))\n",
    "    \n",
    "nb_samples = len(text_pairs)\n",
    "    \n",
    "random.Random().shuffle(text_pairs)\n",
    "validation_index = int(nb_samples * validation_split)\n",
    "\n",
    "train_pairs = text_pairs[:validation_index]\n",
    "validation_pairs = text_pairs[validation_index:]"
   ],
   "id": "a4f99f3572cff163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Text vectorization\n",
    "\n",
    "As the vocabulary is different in both cases, we use separate vectorization layers.\n",
    "\n",
    "BE CAREFUL:\n",
    "\n",
    "- Spanish vectorizer should have one more sequence element, as we'll be padding these sentences\n",
    "- We map BATCHES, so \"english\" and \"spanish\" are size (batch_size, sequence_length)"
   ],
   "id": "f4286a50e8a6332e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_features = 20_000\n",
    "max_sequence_length = 20\n",
    "\n",
    "strip_chars = (string.punctuation + \"¿¡\").replace('[', '').replace(']', '')\n",
    "\n",
    "def target_standardize(input):\n",
    "  lower = tf.strings.lower(input)\n",
    "  return tf.strings.regex_replace(lower, f'[{re.escape(strip_chars)}]', '')\n",
    "\n",
    "# We use 'int' output as we want sequences (each text is short enough for this purpose)\n",
    "english_vectorizer = keras.layers.TextVectorization(\n",
    "  max_tokens=num_features,\n",
    "  output_sequence_length=max_sequence_length,\n",
    "  output_mode='int'\n",
    ")\n",
    "spanish_vectorizer = keras.layers.TextVectorization(\n",
    "  max_tokens=num_features,\n",
    "  output_sequence_length=max_sequence_length + 1,  # We'll need to offset spanish sentences\n",
    "  output_mode='int',\n",
    "  standardize=target_standardize\n",
    ")\n",
    "\n",
    "# Automatically learning the vocabulary from the sentences\n",
    "english_sentences = [pair[0] for pair in train_pairs]\n",
    "spanish_sentences = [pair[1] for pair in train_pairs]\n",
    "english_vectorizer.adapt(english_sentences)\n",
    "spanish_vectorizer.adapt(spanish_sentences)"
   ],
   "id": "74a98c2ece64cfbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "\n",
    "def get_dataset_element(english, spanish):\n",
    "  # We map BATCHES, so \"english\" and \"spanish\" are size (batch_size, sequence_length)\n",
    "  english = english_vectorizer(english)\n",
    "  spanish = spanish_vectorizer(spanish)\n",
    "  return (\n",
    "      {\n",
    "        'english': english,\n",
    "        'spanish': spanish[:, :-1]\n",
    "      },\n",
    "    spanish[:, 1:]\n",
    "  )\n",
    "\n",
    "def make_dataset(pairs):\n",
    "  english_texts, spanish_texts = zip(*pairs)\n",
    "  english_texts = list(english_texts)\n",
    "  spanish_texts = list(spanish_texts)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((english_texts, spanish_texts))\n",
    "  dataset = dataset.batch(batch_size)\n",
    "  dataset = dataset.map(get_dataset_element, num_parallel_calls=4)\n",
    "  # Prefetching enables faster performances when taking elements of the dataset\n",
    "  # Caching is also beneficial for performance\n",
    "  return dataset.shuffle(buffer_size=2048).prefetch(16).cache()\n",
    "  \n",
    "train_dataset = make_dataset(train_pairs)\n",
    "validation_dataset = make_dataset(validation_pairs)"
   ],
   "id": "c1172601e90e5d7b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Useful layers",
   "id": "6ca5775ae4f089c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Positional encoding",
   "id": "dcfbd56686b7502c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class PositionalEmbedding(keras.layers.Layer):\n",
    "  def __init__(self, input_dim, sequence_length, output_dim, **kwargs):\n",
    "    super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "    self.token_embedding = keras.layers.Embedding(\n",
    "      input_dim=input_dim,\n",
    "      output_dim=output_dim,\n",
    "    )\n",
    "    self.position_embedding = keras.layers.Embedding(\n",
    "      input_dim=sequence_length,\n",
    "      output_dim=output_dim,\n",
    "    )\n",
    "      \n",
    "    # Storing variables is always useful\n",
    "    self.input_dim = input_dim\n",
    "    self.sequence_length = sequence_length\n",
    "    self.output_dim = output_dim\n",
    "      \n",
    "  def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update({\n",
    "      'input_dim': self.input_dim,\n",
    "      'sequence_length': self.sequence_length,\n",
    "      'output_dim': self.output_dim,\n",
    "    })\n",
    "    return config\n",
    "      \n",
    "  def call(self, inputs):\n",
    "    # Computing the position is as simple as creating a range with the same size...\n",
    "    batch_size, sequence_length = inputs.shape[0], inputs.shape[-1]\n",
    "    positions = inputs\n",
    "    if sequence_length is not None:\n",
    "      positions = tf.zeros((batch_size, max_sequence_length), dtype=np.int32) + tf.range(0, max_sequence_length)\n",
    "    return keras.layers.add((self.position_embedding(positions), self.token_embedding(inputs)))\n",
    "  \n",
    "  # The mask is a (num_samples, embedding_dim) 2D matrix to indicate which value should be kept (1) or not (0)\n",
    "  # This option is necessary for embedding layers\n",
    "  def compute_mask(self, inputs, mask=None):\n",
    "    return keras.ops.not_equal(inputs, 0)"
   ],
   "id": "e7d8c14f6b14e78b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer encoder",
   "id": "fdf95268915c8ead"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerEncoder(keras.layers.Layer):\n",
    "  # Always pass **kwargs to the top class\n",
    "  def __init__(self, embedding_dim, dense_dim, num_heads, **kwargs):\n",
    "    super(TransformerEncoder, self).__init__(**kwargs)\n",
    "    self.attention = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
    "    self.dense = keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(units=dense_dim, activation='relu'),\n",
    "      tf.keras.layers.Dense(embedding_dim)\n",
    "    ])\n",
    "    \n",
    "    self.normalization1 = keras.layers.LayerNormalization()\n",
    "    self.normalization2 = keras.layers.LayerNormalization()\n",
    "      \n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.dense_dim = dense_dim\n",
    "    self.num_heads = num_heads\n",
    "      \n",
    "    self.supports_masking=True\n",
    "  \n",
    "  def call(self, inputs, mask=None):\n",
    "    if mask is not None:\n",
    "      mask = mask[:, tf.newaxis, :]\n",
    "    \n",
    "    connection = inputs\n",
    "    x = self.attention(query=inputs, key=inputs, value=inputs, attention_mask=mask)\n",
    "    x = keras.layers.add((connection, x))\n",
    "    x = self.normalization1(x)\n",
    "    \n",
    "    residual = x\n",
    "    x = self.dense(x)\n",
    "    x = keras.layers.add((residual, x))\n",
    "\n",
    "    output = self.normalization2(x)\n",
    "    return output\n",
    "    \n",
    "  def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update({\n",
    "      'num_heads': self.num_heads,\n",
    "      'embedding_dim': self.embedding_dim,\n",
    "      'dense_dim': self.dense_dim,\n",
    "    })\n",
    "    return config"
   ],
   "id": "2ea33fdb40298142",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer decoder",
   "id": "96e1a1660c832c09"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class TransformerDecoder(keras.layers.Layer):\n",
    "  def __init__(self, embedding_dim, dense_dim, num_heads, **kwargs):\n",
    "    super(TransformerDecoder, self).__init__(**kwargs)\n",
    "    self.self_attention = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
    "    self.cross_attention = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embedding_dim)\n",
    "    \n",
    "    self.dense = keras.models.Sequential([\n",
    "      tf.keras.layers.Dense(units=dense_dim, activation='relu'),\n",
    "      tf.keras.layers.Dense(embedding_dim)\n",
    "    ])\n",
    "    \n",
    "    self.normalization1 = keras.layers.LayerNormalization()\n",
    "    self.normalization2 = keras.layers.LayerNormalization()\n",
    "    self.normalization3 = keras.layers.LayerNormalization()\n",
    "      \n",
    "    self.num_heads = num_heads\n",
    "    self.embedding_dim = embedding_dim\n",
    "    self.dense_dim = dense_dim\n",
    "      \n",
    "    self.supports_masking=True\n",
    "      \n",
    "  def get_causal_attention_mask(self, inputs):\n",
    "    batch_size, sequence_length = inputs.shape[0], inputs.shape[1]\n",
    "    if sequence_length is None:\n",
    "      return None\n",
    "    \n",
    "    # Step 1: creating the (sequence_length, sequence_length) matrix for 1 sequence\n",
    "    i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "    j = tf.range(sequence_length)\n",
    "    mask = tf.cast(i >= j, dtype=np.int32)\n",
    "    \n",
    "    # Step 2: replicating it for (batch_size) inputs\n",
    "    \n",
    "    # Formally adding the dimension\n",
    "    mask = tf.reshape(mask, (1, sequence_length, sequence_length))\n",
    "    # Tiling in the batch_size direction\n",
    "    return tf.tile(mask, [batch_size, 1, 1])\n",
    "      \n",
    "\n",
    "  def call(self, inputs, encoded_source, mask=None):\n",
    "    causal_mask = self.get_causal_attention_mask(inputs)\n",
    "    if mask is not None:\n",
    "      mask = mask[:, tf.newaxis, :]\n",
    "      mask = tf.minimum(mask, causal_mask)\n",
    "\n",
    "    connection1 = inputs\n",
    "    x = self.self_attention(\n",
    "      query=inputs,\n",
    "      key=inputs, \n",
    "      value=inputs,\n",
    "      attention_mask=causal_mask\n",
    "    )\n",
    "    x = tf.keras.layers.add((connection1, x))\n",
    "    x = self.normalization1(x)\n",
    "\n",
    "    connection2 = x\n",
    "    # We put a special mask here for each word to ignore future words\n",
    "    x = self.cross_attention(\n",
    "      query=x,\n",
    "      key=encoded_source,\n",
    "      value=encoded_source,\n",
    "      attention_mask=mask\n",
    "    )\n",
    "    x = tf.keras.layers.add((connection2, x))\n",
    "    x = self.normalization2(x)\n",
    "    \n",
    "    residual = x\n",
    "    x = self.dense(x)\n",
    "    x = tf.keras.layers.add((residual, x))\n",
    "    return self.normalization3(x)\n",
    "    \n",
    "  def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update({\n",
    "      'num_heads': self.num_heads,\n",
    "      'embedding_dim': self.embedding_dim,\n",
    "      'dense_dim': self.dense_dim,\n",
    "    })\n",
    "    return config"
   ],
   "id": "6f64d2ea6e0e963a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer model",
   "id": "776e7324d62dfa88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, vocabulary_size, sequence_length, embedding_dim, dense_dim, num_heads, encoder_name, decoder_name, dropout_rate=0.5, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.encoder_embedding = PositionalEmbedding(vocabulary_size, sequence_length, embedding_dim)\n",
    "    self.decoder_embedding = PositionalEmbedding(vocabulary_size, sequence_length, embedding_dim)\n",
    "      \n",
    "    self.encoder = TransformerEncoder(embedding_dim, dense_dim, num_heads)\n",
    "    self.decoder = TransformerDecoder(embedding_dim, dense_dim, num_heads)\n",
    "    self.probabilities_output = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "      tf.keras.layers.Dense(units=vocabulary_size, activation='softmax')\n",
    "    ])\n",
    "      \n",
    "    self.encoder_name = encoder_name\n",
    "    self.decoder_name = decoder_name\n",
    "      \n",
    "  def call(self, inputs):\n",
    "    print(inputs)\n",
    "    encoder_input = self.encoder_embedding(inputs[self.encoder_name])\n",
    "    decoder_input = self.decoder_embedding(inputs[self.decoder_name])\n",
    "    \n",
    "    encoder_output = self.encoder(encoder_input)\n",
    "    decoder_output = self.decoder(decoder_input, encoder_output)\n",
    "    return self.probabilities_output(decoder_output)"
   ],
   "id": "f407a785ef2587fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embedding_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "dropout_rate = 0.5\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(num_features, max_sequence_length, embedding_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embedding_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(num_features, max_sequence_length, embedding_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embedding_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "outputs = keras.layers.Dense(units=num_features, activation='softmax')(x)\n",
    "\n",
    "transformer_model = keras.Model(inputs=(encoder_inputs, decoder_inputs), outputs=outputs)\n",
    "\n",
    "transformer_model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "id": "dbecd7f29908f9a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "transformer_model.summary()\n",
    "keras.utils.plot_model(\n",
    "  transformer_model,\n",
    "  show_shapes=True,\n",
    "  show_dtype=True,\n",
    "  show_layer_names=True,\n",
    "  show_layer_activations=True,\n",
    "  expand_nested=True\n",
    ")"
   ],
   "id": "abea783c0fa354f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "date = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "transformer_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.ModelCheckpoint(f'models/transformer_best.keras', save_best_only=True, monitor='val_loss'),\n",
    "        tf.keras.callbacks.ModelCheckpoint('models/transformer{epoch:02d}-{val_loss:.2f}.keras'),\n",
    "        tf.keras.callbacks.BackupAndRestore(backup_dir=f'/tmp/backup/transformer--{date}'),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=f'logs/fit/transformer--{date}', histogram_freq=1)\n",
    "    ]\n",
    ")"
   ],
   "id": "c3aaab7a1ce44e28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing with never-before seen data",
   "id": "49050c7ea6ac7a10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T13:08:22.946348Z",
     "start_time": "2024-08-18T13:08:20.977008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_transformer = keras.models.load_model(\n",
    "  'models/transformer10-2.43.keras',\n",
    "  custom_objects={\n",
    "    \"TransformerEncoder\": TransformerEncoder,\n",
    "    \"TransformerDecoder\": TransformerDecoder,\n",
    "    \"PositionalEmbedding\": PositionalEmbedding\n",
    "  }\n",
    ")"
   ],
   "id": "8b173180c84073b5",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T13:08:22.978069Z",
     "start_time": "2024-08-18T13:08:22.947807Z"
    }
   },
   "cell_type": "code",
   "source": "best_transformer.summary()",
   "id": "d84d3be2e61f94f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_20\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_20\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m5,125,120\u001B[0m │ english[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mPositionalEmbeddi…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_12        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ english[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mNotEqual\u001B[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m5,125,120\u001B[0m │ spanish[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n",
       "│ (\u001B[38;5;33mPositionalEmbeddi…\u001B[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m3,155,456\u001B[0m │ positional_embed… │\n",
       "│ (\u001B[38;5;33mTransformerEncode…\u001B[0m │                   │            │ not_equal_12[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │  \u001B[38;5;34m5,259,520\u001B[0m │ positional_embed… │\n",
       "│ (\u001B[38;5;33mTransformerDecode…\u001B[0m │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_27          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m) │          \u001B[38;5;34m0\u001B[0m │ transformer_deco… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m,      │  \u001B[38;5;34m5,140,000\u001B[0m │ dropout_27[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n",
       "│                     │ \u001B[38;5;34m20000\u001B[0m)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ english             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spanish             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125,120</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_12        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ english[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ positional_embeddi… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,125,120</span> │ spanish[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PositionalEmbeddi…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_encode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,155,456</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │ not_equal_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ transformer_decode… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,259,520</span> │ positional_embed… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ transformer_enco… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_27          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ transformer_deco… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │  <span style=\"color: #00af00; text-decoration-color: #00af00\">5,140,000</span> │ dropout_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)            │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m47,610,434\u001B[0m (181.62 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">47,610,434</span> (181.62 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m23,805,216\u001B[0m (90.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,805,216</span> (90.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Optimizer params: \u001B[0m\u001B[38;5;34m23,805,218\u001B[0m (90.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,805,218</span> (90.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Output of the model is of shape (batch_size, sequence_length, nb_features). Each value (:, i, j) corresponds to the probability that word number i is at position j in the vocabulary.",
   "id": "e1efa2efb260b865"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T13:09:36.788784Z",
     "start_time": "2024-08-18T13:09:33.326149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spanish_vocabulary = spanish_vectorizer.get_vocabulary()\n",
    "\n",
    "def get_translation(english_sentence):\n",
    "  tokenized_english = english_vectorizer([english_sentence])\n",
    "  output_sentence = \"[start]\"\n",
    "  for i in range(max_sequence_length):\n",
    "    tokenized_spanish = spanish_vectorizer([output_sentence])[:, :-1]  # Remember to apply the offset\n",
    "    prediction = best_transformer({\n",
    "      'english': tokenized_english,\n",
    "      'spanish': tokenized_spanish\n",
    "    })\n",
    "    prediction_index = np.argmax(prediction[0, i, :])\n",
    "    prediction_word = spanish_vocabulary[prediction_index]\n",
    "    output_sentence += f' {prediction_word}'\n",
    "    if prediction_word == '[end]':\n",
    "      break    \n",
    "      \n",
    "  return output_sentence\n",
    "\n",
    "for sentence in random.sample(english_sentences, 5):\n",
    "  print(sentence)\n",
    "  print(f'- {get_translation(sentence)}')\n",
    "  print()"
   ],
   "id": "f784f3cd1d04a664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spring is in the air.\n",
      "- [start] [end]\n",
      "\n",
      "She was too proud to ask him for help.\n",
      "- [start] [end]\n",
      "\n",
      "Tom didn't know Mary had decided to leave him.\n",
      "- [start] [end]\n",
      "\n",
      "They are leaving Japan tomorrow.\n",
      "- [start] [end]\n",
      "\n",
      "What time do you want me to pick you up?\n",
      "- [start] [end]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T13:08:53.317121Z",
     "start_time": "2024-08-18T13:08:26.928932Z"
    }
   },
   "cell_type": "code",
   "source": "best_transformer.evaluate(validation_dataset)",
   "id": "75ba6454b89fc654",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theovld/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_4' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "/home/theovld/.local/lib/python3.10/site-packages/keras/src/layers/layer.py:915: UserWarning: Layer 'sequential_5' (of type Sequential) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
      "  warnings.warn(\n",
      "W0000 00:00:1723986508.931206   35980 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 178/1488\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m54s\u001B[0m 42ms/step - accuracy: 0.6802 - loss: 6.3533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1723986518.412503   35980 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m 460/1488\u001B[0m \u001B[32m━━━━━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━\u001B[0m \u001B[1m50s\u001B[0m 49ms/step - accuracy: 0.6814 - loss: 6.3405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1ceac0d4bc130fef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
